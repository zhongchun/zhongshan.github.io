<!DOCTYPE HTML>
<html lang="zh-CN">
<head>
    

<head><meta name="generator" content="Hexo 3.8.0">
    <meta charset="utf-8">
    <meta name="keywords" content="Notes-深度学习入门之卷积神经网络, Machine Learning, Big Data">
    <meta name="description" content="本章的主题是卷积神经网络（Convolutional Neural Network，CNN）。CNN 被用于图像识别、语音识别等各种场合，在图像识别的比赛中，基于深度学习的方法几乎都以 CNN 为基础。
整体结构首先，来看一下 CNN 的网">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <title>Notes-深度学习入门之卷积神经网络 | BerMaker</title>
    <link rel="icon" type="image/png" href="/favicon.png">

    <link rel="stylesheet" type="text/css" href="/libs/awesome/css/font-awesome.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/materialize/css/materialize.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/aos/aos.css">
    <link rel="stylesheet" type="text/css" href="/libs/animate/animate.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/lightGallery/css/lightgallery.min.css">
    <link rel="stylesheet" type="text/css" href="/css/matery.css">
    <link rel="stylesheet" type="text/css" href="/css/my.css">

    <script src="/libs/jquery/jquery-2.2.0.min.js"></script>
<link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css"></head>

</head>

<body>

<header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="container">
            <div class="nav-wrapper">
                <div class="brand-logo">
                    <a href="/" class="waves-effect waves-light">
                        
                        <img src="/medias/logo.png" class="logo-img hide-on-small-only">
                        
                        <span class="logo-span">BerMaker</span>
                    </a>
                </div>
                

<a href="#" data-activates="mobile-nav" class="button-collapse"><i class="fa fa-navicon"></i></a>
<ul class="right">
    
    <li class="hide-on-med-and-down">
        <a href="/" class="waves-effect waves-light">
            
            <i class="fa fa-home"></i>
            
            <span>首页</span>
        </a>
    </li>
    
    <li class="hide-on-med-and-down">
        <a href="/tags" class="waves-effect waves-light">
            
            <i class="fa fa-tags"></i>
            
            <span>标签</span>
        </a>
    </li>
    
    <li class="hide-on-med-and-down">
        <a href="/categories" class="waves-effect waves-light">
            
            <i class="fa fa-bookmark"></i>
            
            <span>分类</span>
        </a>
    </li>
    
    <li class="hide-on-med-and-down">
        <a href="/archives" class="waves-effect waves-light">
            
            <i class="fa fa-archive"></i>
            
            <span>归档</span>
        </a>
    </li>
    
    <li class="hide-on-med-and-down">
        <a href="/about" class="waves-effect waves-light">
            
            <i class="fa fa-user-circle-o"></i>
            
            <span>关于</span>
        </a>
    </li>
    
    <li class="hide-on-med-and-down">
        <a href="/friends" class="waves-effect waves-light">
            
            <i class="fa fa-address-book"></i>
            
            <span>友情链接</span>
        </a>
    </li>
    
    <li>
        <a id="toggleSearch" class="waves-effect waves-light">
            <i id="searchIcon" class="mdi-action-search" title="搜索"></i>
        </a>
    </li>

</ul>

<div class="side-nav" id="mobile-nav">

    <div class="mobile-head bg-color">
        
        <img src="/medias/logo.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">BerMaker</div>
        <div class="logo-desc">
            
            If not now, when? If not you, who?
            
        </div>
    </div>

    

    <ul class="menu-list mobile-menu-list">
        
        <li>
            <a href="/" class="waves-effect waves-light">
                
                <i class="fa fa-fw fa-home"></i>
                
                首页
            </a>
        </li>
        
        <li>
            <a href="/tags" class="waves-effect waves-light">
                
                <i class="fa fa-fw fa-tags"></i>
                
                标签
            </a>
        </li>
        
        <li>
            <a href="/categories" class="waves-effect waves-light">
                
                <i class="fa fa-fw fa-bookmark"></i>
                
                分类
            </a>
        </li>
        
        <li>
            <a href="/archives" class="waves-effect waves-light">
                
                <i class="fa fa-fw fa-archive"></i>
                
                归档
            </a>
        </li>
        
        <li>
            <a href="/about" class="waves-effect waves-light">
                
                <i class="fa fa-fw fa-user-circle-o"></i>
                
                关于
            </a>
        </li>
        
        <li>
            <a href="/friends" class="waves-effect waves-light">
                
                <i class="fa fa-fw fa-address-book"></i>
                
                友情链接
            </a>
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/zhongchun" class="waves-effect waves-light" target="_blank">
                <i class="fa fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>

    <div class="social-link">
    <a href="https://github.com/zhongchun" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fa fa-github"></i>
    </a>



    <a href="mailto:495571751@qq.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fa fa-envelope-open"></i>
    </a>



    <a href="/atom.xml" class="tooltipped" target="_blank" data-tooltip="RSS 订阅" data-position="top" data-delay="50">
        <i class="fa fa-rss"></i>
    </a>

</div>
</div>

            </div>
        </div>

        
        <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/zhongchun" class="github-corner tooltipped hide-on-med-and-down" target="_blank" data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewbox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"/>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"/>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"/>
    </svg>
</a>
        
    </nav>
</header>





<div class="bg-cover post-cover" style="background-image: url('/images/cnn.jpg')">
    <div class="container">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <div class="description center-align post-title">
                        Notes-深度学习入门之卷积神经网络
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>



<main class="post-container content">

    
    <link rel="stylesheet" href="/libs/tocbot/tocbot.css">
<style>
    #articleContent h1,
    #articleContent h2,
    #articleContent h3,
    #articleContent h4,
    #articleContent h5,
    #articleContent h6 {
        padding-top: 76px;
        margin-top: -76px;
    }

    #articleContent h1 {
        line-height: 3.5rem;
    }

    #articleContent h2 {
        line-height: 3.2rem;
    }

    #articleContent h3 {
        line-height: 2.8rem;
    }

    #articleContent h4 {
        line-height: 2.5rem;
    }

    #articleContent h5 {
        line-height: 2.2rem;
    }

    #articleContent h6 {
        line-height: 1.9rem;
    }

    #articleContent :focus {
        outline: none;
    }

    .toc-fixed {
        position: fixed;
        top: 64px;
    }

    .toc-widget {
        padding-left: 20px;
    }

    .toc-widget .toc-title {
        margin: 35px 0 15px 0;
        padding-left: 17px;
        font-size: 1.5rem;
        font-weight: bold;
        line-height: 1.5rem;
    }

    .toc-widget ol {
        padding: 0;
        list-style: none;
    }

    #toc-content ol {
        padding-left: 10px;
    }

    #toc-content ol li {
        padding-left: 10px;
    }

    #toc-content .toc-link:hover {
        color: #42b983;
        font-weight: 700;
        text-decoration: underline;
    }

    #toc-content .toc-link::before {
        background-color: transparent;
        max-height: 25px;
    }

    #toc-content .is-active-link {
        color: #42b983;
    }

    #toc-content .is-active-link::before {
        background-color: #42b983;
    }
</style>
<div class="row">
    <div class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/tags/Notes/" target="_blank">
                                <span class="chip bg-color">Notes</span>
                            </a>
                        
                            <a href="/tags/Deep-Learning/" target="_blank">
                                <span class="chip bg-color">Deep Learning</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fa fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/categories/Deep-Learning/" class="post-category" target="_blank">
                                Deep Learning
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                <div class="post-date info-break-policy">
                    <i class="fa fa-calendar-minus-o fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2018-11-17
                </div>

                
                    
                    <div class="info-break-policy">
                        <i class="fa fa-file-word-o fa-fw"></i>文章字数:&nbsp;&nbsp;
                        6.2k
                    </div>
                    

                    
                    <div class="info-break-policy">
                        <i class="fa fa-clock-o fa-fw"></i>阅读时长:&nbsp;&nbsp;
                        22 分
                    </div>
                    
                
				
				
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="fa fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">
        <div class="card-content article-card-content">
            <div id="articleContent">
                <p>本章的主题是卷积神经网络（Convolutional Neural Network，CNN）。CNN 被用于图像识别、语音识别等各种场合，在图像识别的比赛中，基于深度学习的方法几乎都以 CNN 为基础。</p>
<h2 id="整体结构"><a href="#整体结构" class="headerlink" title="整体结构"></a>整体结构</h2><p>首先，来看一下 CNN 的网络结构，了解 CNN 的大致框架。CNN 和之前介绍的神经网络一样，可以像乐高积木一样通过组装层来构建。不过，CNN 中新出现了卷积层（Convolution 层）和池化层（Pooling 层）。</p>
<p>之前介绍的神经网络中，相邻层的所有神经元之间都有连接，这称为<strong>全连接</strong>（fully-connected）。另外，我们用 Affine 层实现了全连接层。如果使用这个 Affine 层，一个 5 层的全连接的神经网络就可以通过图 7-1 所示的网络结构来实现。</p>
<p><img src="https://ws2.sinaimg.cn/large/006tKfTcly1g09lexh5u3j30rs05tjrr.jpg" alt="116"></p>
<p><strong>图 7-1　基于全连接层（Affine 层）的网络的例子</strong></p>
<p>那么，CNN 会是什么样的结构呢？图 7-2 是 CNN 的一个例子。</p>
<p><img src="https://note.youdao.com/yws/api/personal/file/WEB2622b8cea05bb93dfd4ec5d901370972?method=download&amp;shareKey=c6573e2a678e9193cca977660653a1c4" alt=""><br>图 7-2　基于 CNN 的网络的例子：新增了 Convolution 层和 Pooling 层（用灰色的方块表示）</p>
<p>如图 7-2 所示，CNN 中新增了 Convolution 层和 Pooling 层。CNN 的层的连接顺序是“Convolution - ReLU -（Pooling）”（Pooling 层有时会被省略）。这可以理解为之前的“Affine - ReLU”连接被替换成了“Convolution - ReLU -（Pooling）”连接。</p>
<h2 id="卷积层"><a href="#卷积层" class="headerlink" title="卷积层"></a>卷积层</h2><p>CNN 中出现了一些特有的术语，比如填充、步幅等。此外，各层中传递的数据是有形状的数据（比如，3 维数据），这与之前的全连接网络不同，因此刚开始学习 CNN 时可能会感到难以理解。</p>
<h3 id="全连接层存在的问题"><a href="#全连接层存在的问题" class="headerlink" title="全连接层存在的问题"></a>全连接层存在的问题</h3><p>全连接层存在什么问题呢？那就是数据的形状被“忽视”了。比如，输入数据是图像时，图像通常是高、长、通道方向上的 3 维形状。但是，向全连接层输入时，需要将 3 维数据拉平为 1 维数据。实际上，前面提到的使用了 MNIST 数据集的例子中，输入图像就是 1 通道、高 28 像素、长 28 像素的（1, 28, 28）形状，但却被排成 1 列，以 784 个数据的形式输入到最开始的 Affine 层。</p>
<p>图像是 3 维形状，这个形状中应该含有重要的空间信息。比如，空间上邻近的像素为相似的值、RBG 的各个通道之间分别有密切的关联性、相距较远的像素之间没有什么关联等，3 维形状中可能隐藏有值得提取的本质模式。但是，因为全连接层会忽视形状，将全部的输入数据作为相同的神经元（同一维度的神经元）处理，所以无法利用与形状相关的信息。</p>
<p>而卷积层可以保持形状不变。当输入数据是图像时，卷积层会以 3 维数据的形式接收输入数据，并同样以 3 维数据的形式输出至下一层。因此，在 CNN 中，可以（有可能）正确理解图像等具有形状的数据。</p>
<p>另外，CNN 中，有时将卷积层的输入输出数据称为<strong>特征图</strong>（feature map）。其中，卷积层的输入数据称为输入特征图（input feature map），输出数据称为输出特征图（output feature map）。本书中将“输入输出数据”和“特征图”作为含义相同的词使用。</p>
<h3 id="卷积运算"><a href="#卷积运算" class="headerlink" title="卷积运算"></a>卷积运算</h3><p>卷积层进行的处理就是卷积运算。卷积运算相当于图像处理中的“滤波器运算”。</p>
<p>在介绍卷积运算时，我们来看一个具体的例子（图 7-3）。</p>
<p><img src="https://note.youdao.com/yws/api/personal/file/WEBf15909006372d6b9c069008a559521e1?method=download&amp;shareKey=6cbf97e9a027243252e5c4336b3a4756" alt=""></p>
<p><strong>图 7-3　卷积运算的例子</strong></p>
<p>如图 7-3 所示，卷积运算对输入数据应用滤波器。在这个例子中，输入数据是有高长方向的形状的数据，滤波器也一样，有高长方向上的维度。假设用（height, width）表示数据和滤波器的形状，则在本例中，输入大小是 (4, 4)，滤波器大小是 (3, 3)，输出大小是 (2, 2)。另外，有的文献中也会用“核”这个词来表示这里所说的“滤波器”。</p>
<p>图 7-4 中展示了卷积运算的计算顺序。<br><img src="https://note.youdao.com/yws/api/personal/file/WEB673015b6631f438b634a82a61526d367?method=download&amp;shareKey=385144cb5d4417bfd4c461bb27c5f4e3" alt=""></p>
<p><strong>图 7-4　卷积运算的计算顺序</strong></p>
<p>在全连接的神经网络中，除了权重参数，还存在偏置。CNN 中，滤波器的参数就对应之前的权重。并且，CNN 中也存在偏置。图 7-3 的卷积运算的例子一直展示到了应用滤波器的阶段。包含偏置的卷积运算的处理流如图 7-5 所示。</p>
<p><img src="https://note.youdao.com/yws/api/personal/file/WEB63763209e64407973220254e163babba?method=download&amp;shareKey=ad7892f18aaf72335924f75b267fcbcd" alt=""><br>图 7-5　卷积运算的偏置：向应用了滤波器的元素加上某个固定值（偏置）</p>
<h3 id="填充"><a href="#填充" class="headerlink" title="填充"></a>填充</h3><p>在进行卷积层的处理之前，有时要向输入数据的周围填入固定的数据（比如 0 等），这称为填充（padding），是卷积运算中经常会用到的处理。比如，在图 7-6 的例子中，对大小为 (4, 4) 的输入数据应用了幅度为 1 的填充。“幅度为 1 的填充”是指用幅度为 1 像素的 0 填充周围。</p>
<p><img src="https://note.youdao.com/yws/api/personal/file/WEB8208a08d5e3017ee1910c75ad2809589?method=download&amp;shareKey=5b97c16afed8e564f003a058ad0f3ece" alt=""></p>
<p><strong>图 7-6　卷积运算的填充处理：向输入数据的周围填入 0（图中用虚线表示填充，并省略了填充的内容“0”）</strong></p>
<pre class=" language-text"><code class="language-text">使用填充主要是为了调整输出的大小。比如，对大小为 (4, 4) 的输入数据应用 (3, 3) 的滤波器时，输出大小变为 (2, 2)，相当于输出大小比输入大小缩小了 2 个元素。这在反复进行多次卷积运算的深度网络中会成为问题。为什么呢？因为如果每次进行卷积运算都会缩小空间，那么在某个时刻输出大小就有可能变为 1，导致无法再应用卷积运算。为了避免出现这样的情况，就要使用填充。在刚才的例子中，将填充的幅度设为 1，那么相对于输入大小 (4, 4)，输出大小也保持为原来的 (4, 4)。因此，卷积运算就可以在保持空间大小不变的情况下将数据传给下一层。
</code></pre>
<h3 id="步幅"><a href="#步幅" class="headerlink" title="步幅"></a>步幅</h3><p>应用滤波器的位置间隔称为<strong>步幅</strong>（stride）。<br>之前的例子中步幅都是 1，如果将步幅设为 2，则如图 7-7 所示，应用滤波器的窗口的间隔变为 2 个元素。</p>
<p><img src="https://note.youdao.com/yws/api/personal/file/WEB6a29890f92a8bfbd5040aff13f6f02e7?method=download&amp;shareKey=f3bd1ac096b8876064ad5c37827d51dd" alt=""><br>图 7-7　步幅为 2 的卷积运算的例子</p>
<p>综上，增大步幅后，输出大小会变小。而增大填充后，输出大小会变大。如果将这样的关系写成算式，会如何呢？接下来，我们看一下对于填充和步幅，如何计算输出大小。</p>
<p>这里，假设输入大小为 (<em>H</em>, <em>W</em>)，滤波器大小为 (<em>FH</em>, <em>FW</em>)，输出大小为 (<em>OH</em>, <em>OW</em>)，填充为 <em>P</em>，步幅为 <em>S</em>。此时，输出大小可通过式 (7.1) 进行计算。</p>
<p><img src="https://ws1.sinaimg.cn/large/006tKfTcly1g09n4a3ybwj30ya09vt9b.jpg" alt="7_71"></p>
<p>注意：当输出大小无法除尽时（结果是小数时），需要采取报错等对策。顺便说一下，根据深度学习的框架的不同，当值无法除尽时，有时会向最接近的整数四舍五入，不进行报错而继续运行。</p>
<h3 id="3-维数据的卷积运算"><a href="#3-维数据的卷积运算" class="headerlink" title="3 维数据的卷积运算"></a>3 维数据的卷积运算</h3><p>之前的卷积运算的例子都是以有高、长方向的 2 维形状为对象的。但是，图像是 3 维数据，除了高、长方向之外，还需要处理通道方向。这里，我们按照与之前相同的顺序，看一下对加上了通道方向的 3 维数据进行卷积运算的例子。</p>
<p>图 7-8 是卷积运算的例子，图 7-9 是计算顺序。这里以 3 通道的数据为例，展示了卷积运算的结果。和 2 维数据时（图 7-3 的例子）相比，可以发现纵深方向（通道方向）上特征图增加了。通道方向上有多个特征图时，会按通道进行输入数据和滤波器的卷积运算，并将结果相加，从而得到输出。</p>
<p><img src="https://note.youdao.com/yws/api/personal/file/WEBe08701d61c00d3cc00852fcc07197f5a?method=download&amp;shareKey=5ef1307fae6e9ba152190d7b95934395" alt=""><br>图 7-8　对 3 维数据进行卷积运算的例子</p>
<p><img src="https://ws1.sinaimg.cn/large/006tKfTcly1g09n77zaz0j30rs14q7az.jpg" alt="124"></p>
<p><strong>图 7-9　对 3 维数据进行卷积运算的计算顺序</strong></p>
<p>需要注意的是，在 3 维数据的卷积运算中，输入数据和滤波器的通道数要设为相同的值。在这个例子中，输入数据和滤波器的通道数一致，均为 3。滤波器大小可以设定为任意值（不过，每个通道的滤波器大小要全部相同）。这个例子中滤波器大小为 (3, 3)，但也可以设定为 (2, 2)、(1, 1)、(5, 5) 等任意值。再强调一下，通道数只能设定为和输入数据的通道数相同的值（本例中为 3）。</p>
<h3 id="结合方块思考"><a href="#结合方块思考" class="headerlink" title="结合方块思考"></a>结合方块思考</h3><p>将数据和滤波器结合长方体的方块来考虑，3 维数据的卷积运算会很容易理解。方块是如图 7-10 所示的 3 维长方体。把 3 维数据表示为多维数组时，书写顺序为（channel, height, width）。</p>
<p>将数据和滤波器结合长方体的方块来考虑，3 维数据的卷积运算会很容易理解。方块是如图 7-10 所示的 3 维长方体。把 3 维数据表示为多维数组时，书写顺序为（channel, height, width）。比如，通道数为 C、高度为 H、长度为 W 的数据的形状可以写成（C, H, W）。滤波器也一样，要按（channel, height, width）的顺序书写。比如，通道数为 C、滤波器高度为 FH（Filter Height）、长度为 FW（Filter Width）时，可以写成（C, FH, FW）。</p>
<p><img src="https://note.youdao.com/yws/api/personal/file/WEB4b7b79f45d662b13643228fc8cb30618?method=download&amp;shareKey=9d7718b0dc1027ef15c69b3bee9c43f5" alt=""><br>图 7-10　结合方块思考卷积运算。请注意方块的形状</p>
<p>在这个例子中，数据输出是 1 张特征图。所谓 1 张特征图，换句话说，就是通道数为 1 的特征图。那么，如果要在通道方向上也拥有多个卷积运算的输出，该怎么做呢？为此，就需要用到多个滤波器（权重）。用图表示的话，如图 7-11 所示。</p>
<p><img src="https://note.youdao.com/yws/api/personal/file/WEBe2d5bdfcd62036320207d7b44f7c249e?method=download&amp;shareKey=f540865080b86b3195b13680ce7fb76e" alt=""><br>图 7-11　基于多个滤波器的卷积运算的例子</p>
<p>图 7-11 中，通过应用 FN 个滤波器，输出特征图也生成了 FN 个。如果将这 FN 个特征图汇集在一起，就得到了形状为 (FN, OH, OW) 的方块。将这个方块传给下一层，就是 CNN 的处理流。</p>
<p>如图 7-11 所示，关于卷积运算的滤波器，也必须考虑滤波器的数量。因此，作为 4 维数据，滤波器的权重数据要按 (output_channel, input_channel, height, width) 的顺序书写。比如，通道数为 3、大小为 5 × 5 的滤波器有 20 个时，可以写成 (20, 3, 5, 5)。</p>
<p>卷积运算中（和全连接层一样）存在偏置。在图 7-11 的例子中，如果进一步追加偏置的加法运算处理，则结果如下面的图 7-12 所示。</p>
<p>图 7-12 中，每个通道只有一个偏置。这里，偏置的形状是 (FN, 1, 1)，滤波器的输出结果的形状是 (FN, OH, OW)。这两个方块相加时，要对滤波器的输出结果 (FN, OH, OW) 按通道加上相同的偏置值。另外，不同形状的方块相加时，可以基于 NumPy 的广播功能轻松实现（1.5.5 节）。</p>
<p><img src="https://note.youdao.com/yws/api/personal/file/WEB0b7ab754dd4e754cf4855a51e23e30b3?method=download&amp;shareKey=2062d2a6ea389cadb07c75d25a631265" alt=""><br>图 7-12　卷积运算的处理流（追加了偏置项）</p>
<h3 id="批处理"><a href="#批处理" class="headerlink" title="批处理"></a>批处理</h3><p>神经网络的处理中进行了将输入数据打包的批处理。之前的全连接神经网络的实现也对应了批处理，通过批处理，能够实现处理的高效化和学习时对 mini-batch 的对应。</p>
<p>我们希望卷积运算也同样对应批处理。为此，需要将在各层间传递的数据保存为 4 维数据。具体地讲，就是按 (batch_num, channel, height, width) 的顺序保存数据。比如，将图 7-12 中的处理改成对 N 个数据进行批处理时，数据的形状如图 7-13 所示。</p>
<p>图 7-13 的批处理版的数据流中，在各个数据的开头添加了批用的维度。像这样，数据作为 4 维的形状在各层间传递。这里需要注意的是，网络间传递的是 4 维数据，对这 N 个数据进行了卷积运算。也就是说，批处理将 N 次的处理汇总成了 1 次进行。</p>
<p><img src="https://note.youdao.com/yws/api/personal/file/WEBcea82a6626794bc00decdd2ad7c77a0f?method=download&amp;shareKey=9e8f1db1e298220e4ba0893d49ce8325" alt=""><br>图 7-13　卷积运算的处理流（批处理）</p>
<h2 id="池化层"><a href="#池化层" class="headerlink" title="池化层"></a>池化层</h2><p>池化是缩小高、长方向上的空间的运算。比如，如图 7-14 所示，进行将 2 × 2 的区域集约成 1 个元素的处理，缩小空间大小。</p>
<p><img src="https://note.youdao.com/yws/api/personal/file/WEBf99371e2c6169960d70aed17cb0381b0?method=download&amp;shareKey=e18ac143e9a415731d6c85e9113a827a" alt=""><br>图 7-14　Max 池化的处理顺序</p>
<p>图 7-14 的例子是按步幅 2 进行 2 × 2 的 Max 池化时的处理顺序。“Max 池化”是获取最大值的运算，“2 × 2”表示目标区域的大小。如图所示，从 2 × 2 的区域中取出最大的元素。此外，这个例子中将步幅设为了 2，所以 2 × 2 的窗口的移动间隔为 2 个元素。另外，一般来说，池化的窗口大小会和步幅设定成相同的值。比如，3 × 3 的窗口的步幅会设为 3，4 × 4 的窗口的步幅会设为 4 等。</p>
<pre class=" language-text"><code class="language-text">除了 Max 池化之外，还有 Average 池化等。相对于 Max 池化是从目标区域中取出最大值，Average 池化则是计算目标区域的平均值。在图像识别领域，主要使用 Max 池化。因此，本书中说到“池化层”时，指的是 Max 池化。
</code></pre>
<h3 id="池化层的特征"><a href="#池化层的特征" class="headerlink" title="池化层的特征"></a>池化层的特征</h3><pre class=" language-text"><code class="language-text">1. 没有要学习的参数

   池化层和卷积层不同，没有要学习的参数。池化只是从目标区域中取最大值（或者平均值），所以不存在要学习的参数。

2. 通道数不发生变化

   经过池化运算，输入数据和输出数据的通道数不会发生变化。

3. 对微小的位置变化具有鲁棒性（健壮）

</code></pre>
<h2 id="卷积层和池化层的实现"><a href="#卷积层和池化层的实现" class="headerlink" title="卷积层和池化层的实现"></a>卷积层和池化层的实现</h2><p>前面我们详细介绍了卷积层和池化层，本节我们就用 Python 来实现这两个层。和第 5 章一样，也给进行实现的类赋予 forward 和 backward 方法，并使其可以作为模块使用。</p>
<p>大家可能会感觉卷积层和池化层的实现很复杂，但实际上，通过使用某种技巧，就可以很轻松地实现。本节将介绍这种技巧，将问题简化，然后再进行卷积层的实现。</p>
<h3 id="4维数组"><a href="#4维数组" class="headerlink" title="4维数组"></a>4维数组</h3><p>如前所述，CNN 中各层间传递的数据是 4 维数据。所谓 4 维数据，比如数据的形状是 (10, 1, 28, 28)，则它对应 10 个高为 28、长为 28、通道为 1 的数据。</p>
<p>像这样，CNN 中处理的是 4 维数据，因此卷积运算的实现看上去会很复杂，但是通过使用下面要介绍的 im2col 这个技巧，问题就会变得很简单。</p>
<h3 id="基于-im2col-的展开"><a href="#基于-im2col-的展开" class="headerlink" title="基于 im2col 的展开"></a>基于 im2col 的展开</h3><p>如果老老实实地实现卷积运算，估计要重复好几层的 for 语句。这样的实现有点麻烦，而且，NumPy 中存在使用 for 语句后处理变慢的缺点（NumPy 中，访问元素时最好不要用 for 语句）。这里，我们不使用 for 语句，而是使用 im2col 这个便利的函数进行简单的实现。</p>
<p>im2col 是一个函数，将输入数据展开以适合滤波器（权重）。如图 7-17 所示，对 3 维的输入数据应用 im2col 后，数据转换为 2 维矩阵（正确地讲，是把包含批数量的 4 维数据转换成了 2 维数据）。</p>
<p><img src="https://note.youdao.com/yws/api/personal/file/WEB1107fd7e4b96749380079bdd75d59f8e?method=download&amp;shareKey=5f6a2613d7af85a7f8eeccf8e85cd742" alt=""><br>图 7-17　im2col 的示意图</p>
<p>im2col 会把输入数据展开以适合滤波器（权重）。具体地说，如图 7-18 所示，对于输入数据，将应用滤波器的区域（3 维方块）横向展开为 1 列。im2col 会在所有应用滤波器的地方进行这个展开处理。</p>
<p><img src="https://note.youdao.com/yws/api/personal/file/WEB34fffb7c7fe8179d1a7ff43ded2b2b66?method=download&amp;shareKey=7a890d742162ad75f322d90b8da61a93" alt=""><br>图 7-18　将滤波器的应用区域从头开始依次横向展开为 1 列</p>
<p>在图 7-18 中，为了便于观察，将步幅设置得很大，以使滤波器的应用区域不重叠。而在实际的卷积运算中，滤波器的应用区域几乎都是重叠的。在滤波器的应用区域重叠的情况下，使用 im2col 展开后，展开后的元素个数会多于原方块的元素个数。因此，使用 im2col 的实现存在比普通的实现消耗更多内存的缺点。但是，汇总成一个大的矩阵进行计算，对计算机的计算颇有益处。比如，在矩阵计算的库（线性代数库）等中，矩阵计算的实现已被高度最优化，可以高速地进行大矩阵的乘法运算。因此，通过归结到矩阵计算上，可以有效地利用线性代数库。</p>
<pre class=" language-text"><code class="language-text">im2col 这个名称是“image to column”的缩写，翻译过来就是“从图像到矩阵”的意思。Caffe、Chainer 等深度学习框架中有名为 im2col 的函数，并且在卷积层的实现中，都使用了 im2col。
</code></pre>
<p>使用 im2col 展开输入数据后，之后就只需将卷积层的滤波器（权重）纵向展开为 1 列，并计算 2 个矩阵的乘积即可（参照图 7-19）。这和全连接层的 Affine层进行的处理基本相同。</p>
<p>如图 7-19 所示，基于 im2col 方式的输出结果是 2 维矩阵。因为 CNN 中数据会保存为 4 维数组，所以要将 2 维输出数据转换为合适的形状。以上就是卷积层的实现流程。</p>
<p><img src="https://note.youdao.com/yws/api/personal/file/WEB49705217a4f0901afab95b2b82c49ef4?method=download&amp;shareKey=b6693c54b87252e1ec6adbbbe1aacfcc" alt=""><br>图 7-19　卷积运算的滤波器处理的细节：将滤波器纵向展开为 1 列，并计算和 im2col 展开的数据的矩阵乘积，最后转换（reshape）为输出数据的大小</p>
<h3 id="卷积层的实现"><a href="#卷积层的实现" class="headerlink" title="卷积层的实现"></a>卷积层的实现</h3><p>本书提供了 im2col 函数，并将这个 im2col 函数作为黑盒（不关心内部实现）使用。im2col 的实现内容在 common/util.py 中，它的实现（实质上）是一个 10 行左右的简单函数。有兴趣的读者可以参考。</p>
<pre class=" language-python"><code class="language-python">im2col <span class="token punctuation">(</span>input_data<span class="token punctuation">,</span> filter_h<span class="token punctuation">,</span> filter_w<span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> pad<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
</code></pre>
<ul>
<li><code>input_data</code>——由（数据量，通道，高，长）的 4 维数组构成的输入数据</li>
<li><code>filter_h</code>——滤波器的高</li>
<li><code>filter_w</code>——滤波器的长</li>
<li><code>stride</code>——步幅</li>
<li><code>pad</code>——填充</li>
</ul>
<h3 id="池化层的实现"><a href="#池化层的实现" class="headerlink" title="池化层的实现"></a>池化层的实现</h3><p>池化层的实现和卷积层相同，都使用 im2col 展开输入数据。不过，池化的情况下，在通道方向上是独立的，这一点和卷积层不同。具体地讲，如图 7-21 所示，池化的应用区域按通道单独展开。</p>
<p><img src="https://note.youdao.com/yws/api/personal/file/WEB85b415850cd3d52b6d21f1f066f1ad39?method=download&amp;shareKey=a885f683a36887f3b41289ef01961bcd" alt=""><br>图 7-21　对输入数据展开池化的应用区域（2×2 的池化的例子）</p>
<p>像这样展开之后，只需对展开的矩阵求各行的最大值，并转换为合适的形状即可（图 7-22）。</p>
<p><img src="https://note.youdao.com/yws/api/personal/file/WEB0d1b6ef0835599a74431633611540a88?method=download&amp;shareKey=883fddbe8f9cb063bbc9285bbd707d36" alt=""><br>图 7-22　池化层的实现流程：池化的应用区域内的最大值元素用灰色表示</p>
<h2 id="CNN-的实现"><a href="#CNN-的实现" class="headerlink" title="CNN 的实现"></a>CNN 的实现</h2><p>我们已经实现了卷积层和池化层，现在来组合这些层，搭建进行手写数字识别的 CNN。这里要实现如图 7-23 所示的 CNN。</p>
<p><img src="https://note.youdao.com/yws/api/personal/file/WEB5c938fd7ffa3ba3460d07ddfabf197cf?method=download&amp;shareKey=cfdb73cddefe292224105158f90f4590" alt=""><br>图 7-23　简单 CNN 的网络构成</p>
<h2 id="CNN-的可视化"><a href="#CNN-的可视化" class="headerlink" title="CNN 的可视化"></a>CNN 的可视化</h2><p>CNN 中用到的卷积层在“观察”什么呢？本节将通过卷积层的可视化，探索 CNN 中到底进行了什么处理。</p>
<h3 id="第1层权重的可视化"><a href="#第1层权重的可视化" class="headerlink" title="第1层权重的可视化"></a>第1层权重的可视化</h3><p>学习前的滤波器是随机进行初始化的，所以在黑白的浓淡上没有规律可循，但学习后的滤波器变成了有规律的图像。</p>
<h3 id="基于分层结构的信息提取"><a href="#基于分层结构的信息提取" class="headerlink" title="基于分层结构的信息提取"></a>基于分层结构的信息提取</h3><p>上面的结果是针对第 1 层的卷积层得出的。第 1 层的卷积层中提取了边缘或斑块等“低级”信息，那么在堆叠了多层的 CNN 中，各层中又会提取什么样的信息呢？根据深度学习的可视化相关的研究 [17][18]，随着层次加深，提取的信息（正确地讲，是反映强烈的神经元）也越来越抽象。</p>
<p>如果堆叠了多层卷积层，则随着层次加深，提取的信息也愈加复杂、抽象，这是深度学习中很有意思的一个地方。最开始的层对简单的边缘有响应，接下来的层对纹理有响应，再后面的层对更加复杂的物体部件有响应。也就是说，随着层次加深，神经元从简单的形状向“高级”信息变化。换句话说，就像我们理解东西的“含义”一样，响应的对象在逐渐变化。</p>
<h2 id="具有代表性的-CNN"><a href="#具有代表性的-CNN" class="headerlink" title="具有代表性的 CNN"></a>具有代表性的 CNN</h2><p>关于 CNN，迄今为止已经提出了各种网络结构。这里，我们介绍其中特别重要的两个网络，一个是在 1998 年首次被提出的 CNN 元祖 LeNet[20]，另一个是在深度学习受到关注的 2012 年被提出的 AlexNet[21]。</p>
<h3 id="LeNet"><a href="#LeNet" class="headerlink" title="LeNet"></a>LeNet</h3><p>LeNet 在 1998 年被提出，是进行手写数字识别的网络。如图 7-27 所示，它有连续的卷积层和池化层（正确地讲，是只“抽选元素”的子采样层），最后经全连接层输出结果。</p>
<p><img src="https://note.youdao.com/yws/api/personal/file/WEBa704a335a795f7ca0a5c8dcebc808524?method=download&amp;shareKey=696e827bb76190e684fd0d7477883b2f" alt=""><br>图 7-27　LeNet 的网络结构</p>
<p>和“现在的 CNN”相比，LeNet 有几个不同点。第一个不同点在于激活函数。LeNet 中使用 sigmoid 函数，而现在的 CNN 中主要使用 ReLU 函数。此外，原始的 LeNet 中使用子采样（subsampling）缩小中间数据的大小，而现在的 CNN 中 Max 池化是主流。</p>
<p>综上，LeNet 与现在的 CNN 虽然有些许不同，但差别并不是那么大。想到 LeNet 是 20 多年前提出的最早的 CNN，还是很令人称奇的。</p>
<h3 id="AlexNet"><a href="#AlexNet" class="headerlink" title="AlexNet"></a>AlexNet</h3><p>在 LeNet 问世 20 多年后，AlexNet 被发布出来。AlexNet 是引发深度学习热潮的导火线，不过它的网络结构和 LeNet 基本上没有什么不同，如图 7-28 所示。</p>
<p><img src="https://note.youdao.com/yws/api/personal/file/WEB5848db07f3935c224933ae3e5e8c25ae?method=download&amp;shareKey=0a6d631670dc823d46347d448652b108" alt=""><br>图 7-28　AlexNet</p>
<p>AlexNet 叠有多个卷积层和池化层，最后经由全连接层输出结果。虽然结构上 AlexNet 和 LeNet 没有大的不同，但有以下几点差异。</p>
<ul>
<li>激活函数使用 ReLU。</li>
<li>使用进行局部正规化的 LRN（Local Response Normalization）层。</li>
<li>使用 Dropout（6.4.3 节）。</li>
</ul>
<p>如上所述，关于网络结构，LeNet 和 AlexNet 没有太大的不同。但是，围绕它们的环境和计算机技术有了很大的进步。具体地说，现在任何人都可以获得大量的数据。而且，擅长大规模并行计算的 GPU 得到普及，高速进行大量的运算已经成为可能。大数据和 GPU 已成为深度学习发展的巨大的原动力。</p>
<pre class=" language-text"><code class="language-text">大多数情况下，深度学习（加深了层次的网络）存在大量的参数。因此，学习需要大量的计算，并且需要使那些参数“满意”的大量数据。可以说是 GPU 和大数据给这些课题带来了希望。
</code></pre>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>构成 CNN 的基本模块的卷积层和池化层虽然有些复杂，但是一旦理解了，之后就只是如何使用它们的问题了。本章为了使读者在实现层面上理解卷积层和池化层，花了不少时间进行介绍。在图像处理领域，几乎毫无例外地都会使用 CNN。请扎实地理解本章的内容，然后进入最后一章的学习。</p>
<p>主要内容：</p>
<ul>
<li>CNN在此前的全连接层的网络中新增了卷积层和池化层。</li>
<li>使用im2col函数可以简单、高效地实现卷积层和池化层。</li>
<li>通过CNN的可视化，可知随着层次变深，提取的信息愈加高级。</li>
<li>LeNet和AlexNet是CNN的代表性网络。</li>
<li>在深度学习的发展中，大数据和GPU做出了很大的贡献。</li>
</ul>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ol>
<li><a href="http://www.ituring.com.cn/book/1921" target="_blank" rel="noopener">深度学习入门：基于Python的理论与实现</a></li>
</ol>

            </div>
            <hr>

            
            <style>
    #reward {
        margin: 40px 0;
        text-align: center;
    }

    #reward .reward-link {
        font-size: 1.88rem;
    }

    #reward .btn-floating:hover {
        box-shadow: 0 6px 12px rgba(0, 0, 0, 0.2), 0 5px 15px rgba(0, 0, 0, 0.2);
    }

    #rewardModal {
        width: 320px;
        height: 350px;
    }

    #rewardModal .reward-title {
        margin: 15px auto;
        padding-bottom: 5px;
    }

    #rewardModal .modal-content {
        padding: 10px;
    }

    #rewardModal .close {
        position: absolute;
        right: 15px;
        top: 15px;
        color: rgba(0, 0, 0, 0.5);
        font-size: 1.3rem;
        line-height: 20px;
        cursor: pointer;
    }

    #rewardModal .reward-tabs {
        margin: 0 auto;
        width: 210px;
    }

    .reward-tabs .tabs {
        height: 38px;
        margin: 10px auto;
        padding-left: 0;
    }

    .reward-tabs .tabs .tab {
        height: 38px;
        line-height: 38px;
    }

    .reward-tabs .tab a {
        color: #fff;
        background-color: #ccc;
    }

    .reward-tabs .tab a:hover {
        color: #fff;
    }

    .reward-tabs .wechat-tab .active {
        color: #fff;
        background-color: #22AB38;
    }

    .reward-tabs .alipay-tab .active {
        color: #fff;
        background-color: #019FE8;
    }

    .reward-tabs .reward-img {
        width: 210px;
        height: 210px;
    }
</style>

<div id="reward">
    <a class="reward-link btn-floating btn-large waves-effect waves-light red">赏</a>

    <!-- Modal Structure -->
    <div id="rewardModal" class="modal">
        <div class="modal-content">
            <a class="close"><i class="fa fa-close"></i></a>
            <h4 class="reward-title">你的赏识是我前进的动力</h4>
            <div class="reward-content">
                <div class="reward-tabs">
                    <ul class="tabs">
                        <li class="tab wechat-tab waves-effect waves-light"><a class="active" href="#wechat">微信</a></li>
                        <li class="tab alipay-tab waves-effect waves-light"><a href="#alipay">支付宝</a></li>
                    </ul>
                    <div id="wechat">
                        <img src="/medias/reward/wechat.jpg" class="reward-img" alt="微信打赏二维码">
                    </div>
                    <div id="alipay">
                        <img src="/medias/reward/alipay.jpg" class="reward-img" alt="支付宝打赏二维码">
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>

<script>
    $(function () {
        $('#reward .reward-link').on('click', function () {
            $('#rewardModal').openModal();
        });

        $('#rewardModal .close').on('click', function () {
            $('#rewardModal').closeModal();
        });
    });
</script>
            

            <link rel="stylesheet" type="text/css" href="/libs/share/css/share.min.css">

<div id="article-share">
    
    <div class="social-share" data-disabled="qzone" data-wechat-qrcode-helper="<p>微信里点“发现”->“扫一扫”二维码便可查看分享。</p>"></div>
    
</div>

<script src="/libs/share/js/social-share.min.js"></script>

            <div class="reprint">
                <p>
                    <span class="reprint-tip">
                        <i class="fa fa-exclamation-circle"></i>&nbsp;&nbsp;转载请注明:
                    </span>
                    <a href="http://yuzhongchun.com" class="b-link-green">BerMaker</a>
                    <i class="fa fa-angle-right fa-lg fa-fw text-color"></i>
                    <a href="/2018/11/17/32-dl-convolutional-neural-network-notes/" class="b-link-green">Notes-深度学习入门之卷积神经网络</a>
                </p>
            </div>
        </div>
    </div>

    
        <link rel="stylesheet" href="/libs/gitalk/gitalk.css">
<link rel="stylesheet" href="/css/my-gitalk.css">

<div class="card gitalk-card" data-aos="fade-up">
    <div id="gitalk-container" class="card-content"></div>
</div>

<script src="/libs/gitalk/gitalk.min.js"></script>
<script>
    let gitalk = new Gitalk({
        clientID: '21ea087c6104923ba888',
        clientSecret: '560f45f0aefc21d726f86ee331bb04fc8660bcf6',
        repo: 'gitalk',
        owner: 'zhongchun',
        admin: "zhongchun",
        id: '2018-11-17T22-38-12',
        distractionFreeMode: false  // Facebook-like distraction free mode
    });

    gitalk.render('gitalk-container');
</script>
    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fa fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/2018/11/22/33-dl-deep-learning-notes/">
                    <div class="card-image">
                        
                        <img src="/images/dnn.jpg" class="responsive-img" alt="Notes-深度学习入门之深度学习">
                        
                        <span class="card-title">Notes-深度学习入门之深度学习</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary">深度学习是加深了层的深度神经网络。基于之前介绍的网络，只需通过叠加层，就可以创建深度网络。本章我们将看一下深度学习的性质、课题和可能性，然后对当前的深度学习进行概括性的说明。
加深网络关于神经网络，我们已经学了很多东西，比如构成神经网络的各</div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="fa fa-clock-o fa-fw icon-date"></i>2018-11-22
                        </span>
                        <span class="publish-author">
                            
                            <i class="fa fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/Deep-Learning/" class="post-category" target="_blank">
                                    Deep Learning
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/Notes/" target="_blank">
                        <span class="chip bg-color">Notes</span>
                    </a>
                    
                    <a href="/tags/Deep-Learning/" target="_blank">
                        <span class="chip bg-color">Deep Learning</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fa fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/2018/11/16/30-dl-learning-skills-notes/">
                    <div class="card-image">
                        
                        <img src="/images/learning-skills.jpg" class="responsive-img" alt="Notes-深度学习入门之与学习相关的技巧">
                        
                        <span class="card-title">Notes-深度学习入门之与学习相关的技巧</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary">本章将介绍神经网络的学习中的一些重要观点，主题涉及寻找最优权重参数的最优化方法、权重参数的初始值、超参数的设定方法等。此外，为了应对过拟合，本章还将介绍权值衰减、Dropout 等正则化方法，并进行实现。最后将对近年来众多研究中使用的 Ba</div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="fa fa-clock-o fa-fw icon-date"></i>2018-11-16
                            </span>
                        <span class="publish-author">
                            
                            <i class="fa fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/Deep-Learning/" class="post-category" target="_blank">
                                    Deep Learning
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/Notes/" target="_blank">
                        <span class="chip bg-color">Notes</span>
                    </a>
                    
                    <a href="/tags/Deep-Learning/" target="_blank">
                        <span class="chip bg-color">Deep Learning</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>
</div>


<script>
    $('#articleContent').on('copy', function (e) {
        // IE8 or earlier browser is 'undefined'
        if (typeof window.getSelection === 'undefined') return;

        var selection = window.getSelection();
        // if the selection is short let's not annoy our users.
        if (('' + selection).length < Number.parseInt('120')) {
            return;
        }

        // create a div outside of the visible area and fill it with the selected text.
        var bodyElement = document.getElementsByTagName('body')[0];
        var newdiv = document.createElement('div');
        newdiv.style.position = 'absolute';
        newdiv.style.left = '-99999px';
        bodyElement.appendChild(newdiv);
        newdiv.appendChild(selection.getRangeAt(0).cloneContents());

        // we need a <pre> tag workaround.
        // otherwise the text inside "pre" loses all the line breaks!
        if (selection.getRangeAt(0).commonAncestorContainer.nodeName === 'PRE') {
            newdiv.innerHTML = "<pre>" + newdiv.innerHTML + "</pre>";
        }

        var url = document.location.href;
        newdiv.innerHTML += '<br />'
            + '来源: BerMaker<br />'
            + '作者: BerMaker<br />'
            + '链接: <a href="' + url + '">' + url + '</a><br />'
            + '本文章著作权归作者所有，任何形式的转载都请注明出处。';

        selection.selectAllChildren(newdiv);
        window.setTimeout(function () {bodyElement.removeChild(newdiv);}, 200);
    });
</script>

    </div>
    <div class="col l3 hide-on-med-and-down">
        <div class="toc-widget">
            <div class="toc-title"><i class="fa fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<script src="/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingSelector: 'h2, h3, h4'
        });

        // modify the toc link href to support Chinese.
        let i = 0;
        let tocHeading = 'toc-heading-';
        $('#toc-content a').each(function () {
            $(this).attr('href', '#' + tocHeading + (++i));
        });

        // modify the heading title id to support Chinese.
        i = 0;
        $('#articleContent').children('h2, h3, h4').each(function () {
            $(this).attr('id', tocHeading + (++i));
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });
    });
</script>
    

</main>


<footer class="page-footer bg-color">
    <div class="container row center-align">
        <div class="col s12 m8 l8 copy-right">
            本站由&copy;<a href="https://blinkfox.github.io/" target="_blank">Blinkfox</a>基于
            <a href="https://hexo.io/" target="_blank">Hexo</a> 的
            <a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">hexo-theme-matery</a>主题搭建.

            
                &nbsp;<i class="fa fa-area-chart"></i>&nbsp;站点总字数:&nbsp;
                <span class="white-color">78.2k</span>
            

            
			
                <br>
                
                <span id="busuanzi_container_site_pv">
                    <i class="fa fa-heart-o"></i>
                    本站总访问量 <span id="busuanzi_value_site_pv" class="white-color"></span>
                </span>
                
                
                <span id="busuanzi_container_site_uv">
                    <i class="fa fa-users"></i>
                    次,&nbsp;访客数 <span id="busuanzi_value_site_uv" class="white-color"></span> 人.
                </span>
                
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/zhongchun" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fa fa-github"></i>
    </a>



    <a href="mailto:495571751@qq.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fa fa-envelope-open"></i>
    </a>



    <a href="/atom.xml" class="tooltipped" target="_blank" data-tooltip="RSS 订阅" data-position="top" data-delay="50">
        <i class="fa fa-rss"></i>
    </a>

</div>
    </div>
</footer>

<div class="progress-bar"></div>


<!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fa fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字" class="search-input" autofocus>
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script src="/js/search.js"></script>
<script type="text/javascript">
    searchFunc("/" + "search.xml", 'searchInput', 'searchResult');
</script>
<!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fa fa-angle-up"></i>
    </a>
</div>


<script src="/libs/materialize/js/materialize.min.js"></script>
<script src="/libs/masonry/masonry.pkgd.min.js"></script>
<script src="/libs/aos/aos.js"></script>
<script src="/libs/scrollprogress/scrollProgress.min.js"></script>
<script src="/libs/lightGallery/js/lightgallery-all.min.js"></script>
<script src="/js/matery.js"></script>

<!-- Global site tag (gtag.js) - Google Analytics -->



    <script src="/libs/others/clicklove.js"></script>


    <script async src="/libs/others/busuanzi.pure.mini.js"></script>


</body>
</html>