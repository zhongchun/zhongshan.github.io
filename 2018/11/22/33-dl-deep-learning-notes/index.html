<!DOCTYPE HTML>
<html lang="zh-CN">
<head>
    

<head><meta name="generator" content="Hexo 3.8.0">
    <meta charset="utf-8">
    <meta name="keywords" content="Notes-深度学习入门之深度学习, Machine Learning, Big Data">
    <meta name="description" content="深度学习是加深了层的深度神经网络。基于之前介绍的网络，只需通过叠加层，就可以创建深度网络。本章我们将看一下深度学习的性质、课题和可能性，然后对当前的深度学习进行概括性的说明。
加深网络关于神经网络，我们已经学了很多东西，比如构成神经网络的各">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <title>Notes-深度学习入门之深度学习 | BerMaker</title>
    <link rel="icon" type="image/png" href="/favicon.png">

    <link rel="stylesheet" type="text/css" href="/libs/awesome/css/font-awesome.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/materialize/css/materialize.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/aos/aos.css">
    <link rel="stylesheet" type="text/css" href="/libs/animate/animate.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/lightGallery/css/lightgallery.min.css">
    <link rel="stylesheet" type="text/css" href="/css/matery.css">
    <link rel="stylesheet" type="text/css" href="/css/my.css">

    <script src="/libs/jquery/jquery-2.2.0.min.js"></script>
<link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css"></head>

</head>

<body>

<header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="container">
            <div class="nav-wrapper">
                <div class="brand-logo">
                    <a href="/" class="waves-effect waves-light">
                        
                        <img src="/medias/logo.png" class="logo-img hide-on-small-only">
                        
                        <span class="logo-span">BerMaker</span>
                    </a>
                </div>
                

<a href="#" data-activates="mobile-nav" class="button-collapse"><i class="fa fa-navicon"></i></a>
<ul class="right">
    
    <li class="hide-on-med-and-down">
        <a href="/" class="waves-effect waves-light">
            
            <i class="fa fa-home"></i>
            
            <span>首页</span>
        </a>
    </li>
    
    <li class="hide-on-med-and-down">
        <a href="/tags" class="waves-effect waves-light">
            
            <i class="fa fa-tags"></i>
            
            <span>标签</span>
        </a>
    </li>
    
    <li class="hide-on-med-and-down">
        <a href="/categories" class="waves-effect waves-light">
            
            <i class="fa fa-bookmark"></i>
            
            <span>分类</span>
        </a>
    </li>
    
    <li class="hide-on-med-and-down">
        <a href="/archives" class="waves-effect waves-light">
            
            <i class="fa fa-archive"></i>
            
            <span>归档</span>
        </a>
    </li>
    
    <li class="hide-on-med-and-down">
        <a href="/about" class="waves-effect waves-light">
            
            <i class="fa fa-user-circle-o"></i>
            
            <span>关于</span>
        </a>
    </li>
    
    <li class="hide-on-med-and-down">
        <a href="/friends" class="waves-effect waves-light">
            
            <i class="fa fa-address-book"></i>
            
            <span>友情链接</span>
        </a>
    </li>
    
    <li>
        <a id="toggleSearch" class="waves-effect waves-light">
            <i id="searchIcon" class="mdi-action-search" title="搜索"></i>
        </a>
    </li>

</ul>

<div class="side-nav" id="mobile-nav">

    <div class="mobile-head bg-color">
        
        <img src="/medias/logo.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">BerMaker</div>
        <div class="logo-desc">
            
            If not now, when? If not you, who?
            
        </div>
    </div>

    

    <ul class="menu-list mobile-menu-list">
        
        <li>
            <a href="/" class="waves-effect waves-light">
                
                <i class="fa fa-fw fa-home"></i>
                
                首页
            </a>
        </li>
        
        <li>
            <a href="/tags" class="waves-effect waves-light">
                
                <i class="fa fa-fw fa-tags"></i>
                
                标签
            </a>
        </li>
        
        <li>
            <a href="/categories" class="waves-effect waves-light">
                
                <i class="fa fa-fw fa-bookmark"></i>
                
                分类
            </a>
        </li>
        
        <li>
            <a href="/archives" class="waves-effect waves-light">
                
                <i class="fa fa-fw fa-archive"></i>
                
                归档
            </a>
        </li>
        
        <li>
            <a href="/about" class="waves-effect waves-light">
                
                <i class="fa fa-fw fa-user-circle-o"></i>
                
                关于
            </a>
        </li>
        
        <li>
            <a href="/friends" class="waves-effect waves-light">
                
                <i class="fa fa-fw fa-address-book"></i>
                
                友情链接
            </a>
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/zhongchun" class="waves-effect waves-light" target="_blank">
                <i class="fa fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>

    <div class="social-link">
    <a href="https://github.com/zhongchun" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fa fa-github"></i>
    </a>



    <a href="mailto:495571751@qq.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fa fa-envelope-open"></i>
    </a>



    <a href="/atom.xml" class="tooltipped" target="_blank" data-tooltip="RSS 订阅" data-position="top" data-delay="50">
        <i class="fa fa-rss"></i>
    </a>

</div>
</div>

            </div>
        </div>

        
        <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/zhongchun" class="github-corner tooltipped hide-on-med-and-down" target="_blank" data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewbox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"/>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"/>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"/>
    </svg>
</a>
        
    </nav>
</header>





<div class="bg-cover post-cover" style="background-image: url('/images/dnn.jpg')">
    <div class="container">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <div class="description center-align post-title">
                        Notes-深度学习入门之深度学习
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>



<main class="post-container content">

    
    <link rel="stylesheet" href="/libs/tocbot/tocbot.css">
<style>
    #articleContent h1,
    #articleContent h2,
    #articleContent h3,
    #articleContent h4,
    #articleContent h5,
    #articleContent h6 {
        padding-top: 76px;
        margin-top: -76px;
    }

    #articleContent h1 {
        line-height: 3.5rem;
    }

    #articleContent h2 {
        line-height: 3.2rem;
    }

    #articleContent h3 {
        line-height: 2.8rem;
    }

    #articleContent h4 {
        line-height: 2.5rem;
    }

    #articleContent h5 {
        line-height: 2.2rem;
    }

    #articleContent h6 {
        line-height: 1.9rem;
    }

    #articleContent :focus {
        outline: none;
    }

    .toc-fixed {
        position: fixed;
        top: 64px;
    }

    .toc-widget {
        padding-left: 20px;
    }

    .toc-widget .toc-title {
        margin: 35px 0 15px 0;
        padding-left: 17px;
        font-size: 1.5rem;
        font-weight: bold;
        line-height: 1.5rem;
    }

    .toc-widget ol {
        padding: 0;
        list-style: none;
    }

    #toc-content ol {
        padding-left: 10px;
    }

    #toc-content ol li {
        padding-left: 10px;
    }

    #toc-content .toc-link:hover {
        color: #42b983;
        font-weight: 700;
        text-decoration: underline;
    }

    #toc-content .toc-link::before {
        background-color: transparent;
        max-height: 25px;
    }

    #toc-content .is-active-link {
        color: #42b983;
    }

    #toc-content .is-active-link::before {
        background-color: #42b983;
    }
</style>
<div class="row">
    <div class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/tags/Notes/" target="_blank">
                                <span class="chip bg-color">Notes</span>
                            </a>
                        
                            <a href="/tags/Deep-Learning/" target="_blank">
                                <span class="chip bg-color">Deep Learning</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fa fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/categories/Deep-Learning/" class="post-category" target="_blank">
                                Deep Learning
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                <div class="post-date info-break-policy">
                    <i class="fa fa-calendar-minus-o fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2018-11-22
                </div>

                
                    
                    <div class="info-break-policy">
                        <i class="fa fa-file-word-o fa-fw"></i>文章字数:&nbsp;&nbsp;
                        11.7k
                    </div>
                    

                    
                    <div class="info-break-policy">
                        <i class="fa fa-clock-o fa-fw"></i>阅读时长:&nbsp;&nbsp;
                        41 分
                    </div>
                    
                
				
				
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="fa fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">
        <div class="card-content article-card-content">
            <div id="articleContent">
                <p>深度学习是加深了层的深度神经网络。基于之前介绍的网络，只需通过叠加层，就可以创建深度网络。本章我们将看一下深度学习的性质、课题和可能性，然后对当前的深度学习进行概括性的说明。</p>
<h2 id="加深网络"><a href="#加深网络" class="headerlink" title="加深网络"></a>加深网络</h2><p>关于神经网络，我们已经学了很多东西，比如构成神经网络的各种层、学习时的有效技巧、对图像特别有效的 CNN、参数的最优化方法等，这些都是深度学习中的重要技术。本节我们将这些已经学过的技术汇总起来，创建一个深度网络，挑战 MNIST 数据集的手写数字识别。</p>
<h3 id="向更深的网络出发"><a href="#向更深的网络出发" class="headerlink" title="向更深的网络出发"></a>向更深的网络出发</h3><p>话不多说，这里我们来创建一个如图 8-1 所示的网络结构的 CNN（一个比之前的网络都深的网络）。这个网络参考了下一节要介绍的 VGG。</p>
<p>如图 8-1 所示，这个网络的层比之前实现的网络都更深。这里使用的卷积层全都是 3 × 3 的小型滤波器，特点是随着层的加深，通道数变大（卷积层的通道数从前面的层开始按顺序以 16、16、32、32、64、64 的方式增加）。此外，如图 8-1 所示，插入了池化层，以逐渐减小中间数据的空间大小；并且，后面的全连接层中使用了 Dropout 层。</p>
<p><img src="https://ws4.sinaimg.cn/large/006tKfTcly1g09s196pxpj30rs0efq41.jpg" alt="144"></p>
<p><strong>图 8-1　进行手写数字识别的深度 CNN</strong></p>
<p>这个网络使用 He 初始值作为权重的初始值，使用 Adam 更新权重参数。把上述内容总结起来，这个网络有如下特点。</p>
<ul>
<li>基于 3×3 的小型滤波器的卷积层。</li>
<li>激活函数是 ReLU。</li>
<li>全连接层的后面使用 Dropout 层。</li>
<li>基于 Adam 的最优化。</li>
<li>使用 He 初始值作为权重初始值。</li>
</ul>
<p>从这些特征中可以看出，图 8-1 的网络中使用了多个之前介绍的神经网络技术。现在，我们使用这个网络进行学习。先说一下结论，这个网络的识别精度为 99.38% {1[最终的识别精度有少许偏差，不过在这个网络中，识别精度大体上都会超过 99%。]}，可以说是非常优秀的性能了！</p>
<h3 id="进一步提高识别精度"><a href="#进一步提高识别精度" class="headerlink" title="进一步提高识别精度"></a>进一步提高识别精度</h3><p>在一个标题为“What is the class of this image ?”的网站 [32] 上，以排行榜的形式刊登了目前为止通过论文等渠道发表的针对各种数据集的方法的识别精度（图 8-3）。</p>
<p><img src="https://ws1.sinaimg.cn/large/006tKfTcly1g09s5nlvoyj30rs0mstgq.jpg" alt="146"></p>
<p><strong>图 8-3　针对 MNIST 数据集的各种方法的排行（引自文献 [32]：2016 年 6 月）</strong></p>
<p>显眼。实际上，排行榜上的前几名大都是基于 CNN 的方法。顺便说一下，截止到 2016 年 6 月，对 MNIST 数据集的最高识别精度是 99.79%（错误识别率为 0.21%），该方法也是以 CNN 为基础的 [33]。不过，它用的 CNN 并不是特别深层的网络（卷积层为 2 层、全连接层为 2 层的网络）。</p>
<pre class=" language-text"><code class="language-text">对于 MNIST 数据集，层不用特别深就获得了（目前）最高的识别精度。一般认为，这是因为对于手写数字识别这样一个比较简单的任务，没有必要将网络的表现力提高到那么高的程度。因此，可以说加深层的好处并不大。而之后要介绍的大规模的一般物体识别的情况，因为问题复杂，所以加深层对提高识别精度大有裨益。
</code></pre>
<p>参考刚才排行榜中前几名的方法，可以发现进一步提高识别精度的技术和线索。比如，集成学习、学习率衰减、<strong>Data Augmentation</strong>（数据扩充）等都有助于提高识别精度。尤其是 Data Augmentation，虽然方法很简单，但在提高识别精度上效果显著。</p>
<p>Data Augmentation 基于算法“人为地”扩充输入图像（训练图像）。具体地说，如图 8-4 所示，对于输入图像，通过施加旋转、垂直或水平方向上的移动等微小变化，增加图像的数量。这在数据集的图像数量有限时尤其有效。</p>
<p><img src="https://ws2.sinaimg.cn/large/006tKfTcly1g09s71ldgbj30rs09140d.jpg" alt="147"></p>
<p><strong>图 8-4　Data Augmentation 的例子</strong></p>
<p>除了如图 8-4 所示的变形之外，Data Augmentation 还可以通过其他各种方法扩充图像，比如裁剪图像的“crop 处理”、将图像左右翻转的“flip 处理”{2[flip 处理只在不需要考虑图像对称性的情况下有效。]}等。对于一般的图像，施加亮度等外观上的变化、放大缩小等尺度上的变化也是有效的。不管怎样，通过 Data Augmentation 巧妙地增加训练图像，就可以提高深度学习的识别精度。虽然这个看上去只是一个简单的技巧，不过经常会有很好的效果。这里，我们不进行 Data Augmentation 的实现，不过这个技巧的实现比较简单，有兴趣的读者请自己试一下。</p>
<h3 id="加深层的动机"><a href="#加深层的动机" class="headerlink" title="加深层的动机"></a>加深层的动机</h3><p>关于加深层的重要性，现状是理论研究还不够透彻。尽管目前相关理论还比较贫乏，但是有几点可以从过往的研究和实验中得以解释（虽然有一些直观）。本节就加深层的重要性，给出一些增补性的数据和说明。</p>
<p>首先，从以 ILSVRC(<a href="http://www.image-net.org/challenges/LSVRC/" target="_blank" rel="noopener">ImageNet Large Scale Visual Recognition Competition</a>) 为代表的大规模图像识别的比赛结果中可以看出加深层的重要性（详细内容请参考下一节）。这种比赛的结果显示，最近前几名的方法多是基于深度学习的，并且有逐渐加深网络的层的趋势。也就是说，可以看到层越深，识别性能也越高。</p>
<p>下面我们说一下加深层的好处。其中一个好处就是可以减少网络的参数数量。说得详细一点，就是与没有加深层的网络相比，加深了层的网络可以用更少的参数达到同等水平（或者更强）的表现力。这一点结合卷积运算中的滤波器大小来思考就好理解了。比如，图 8-5 展示了由 5 × 5 的滤波器构成的卷积层。</p>
<p><img src="https://ws1.sinaimg.cn/large/006tKfTcly1g09sa2n35cj30rs0d2mys.jpg" alt="148"></p>
<p><strong>图 8-5　5×5 的卷积运算的例子</strong></p>
<p>这里希望大家考虑一下输出数据的各个节点是从输入数据的哪个区域计算出来的。显然，在图 8-5 的例子中，每个输出节点都是从输入数据的某个 5 × 5 的区域算出来的。接下来我们思考一下图 8-6 中重复两次 3 × 3 的卷积运算的情形。此时，每个输出节点将由中间数据的某个 3 × 3 的区域计算出来。那么，中间数据的 3 × 3 的区域又是由前一个输入数据的哪个区域计算出来的呢？仔细观察图 8-6，可知它对应一个 5 × 5 的区域。也就是说，图 8-6 的输出数据是“观察”了输入数据的某个 5 × 5 的区域后计算出来的。</p>
<p><img src="https://ws3.sinaimg.cn/large/006tKfTcly1g09sbkicufj30rs08jwg3.jpg" alt="149"></p>
<p><strong>图 8-6　重复两次 3×3 的卷积层的例子</strong></p>
<p>一次 5 × 5 的卷积运算的区域可以由两次 3 × 3 的卷积运算抵充。并且，相对于前者的参数数量 25（5 × 5），后者一共是 18（2 × 3 × 3），通过叠加卷积层，参数数量减少了。而且，这个参数数量之差会随着层的加深而变大。比如，重复三次 3 × 3 的卷积运算时，参数的数量总共是 27。而为了用一次卷积运算“观察”与之相同的区域，需要一个 7 × 7 的滤波器，此时的参数数量是 49。</p>
<pre class=" language-text"><code class="language-text">叠加小型滤波器来加深网络的好处是可以减少参数的数量，扩大感受野（receptive field，给神经元施加变化的某个局部空间区域）。并且，通过叠加层，将 ReLU 等激活函数夹在卷积层的中间，进一步提高了网络的表现力。这是因为向网络添加了基于激活函数的“非线性”表现力，通过非线性函数的叠加，可以表现更加复杂的东西。
</code></pre>
<p>加深层的另一个好处就是使学习更加高效。与没有加深层的网络相比，通过加深层，可以减少学习数据，从而高效地进行学习。为了直观地理解这一点，大家可以回忆一下 7.6 节的内容。7.6 节中介绍了 CNN 的卷积层会分层次地提取信息。具体地说，在前面的卷积层中，神经元会对边缘等简单的形状有响应，随着层的加深，开始对纹理、物体部件等更加复杂的东西有响应。</p>
<p>我们先牢记这个网络的分层结构，然后考虑一下“狗”的识别问题。要用浅层网络解决这个问题的话，卷积层需要一下子理解很多“狗”的特征。“狗”有各种各样的种类，根据拍摄环境的不同，外观变化也很大。因此，要理解“狗”的特征，需要大量富有差异性的学习数据，而这会导致学习需要花费很多时间。</p>
<p>不过，通过加深网络，就可以分层次地分解需要学习的问题。因此，各层需要学习的问题就变成了更简单的问题。比如，最开始的层只要专注于学习边缘就好，这样一来，只需用较少的学习数据就可以高效地进行学习。这是为什么呢？因为和印有“狗”的照片相比，包含边缘的图像数量众多，并且边缘的模式比“狗”的模式结构更简单。</p>
<p>通过加深层，可以分层次地传递信息，这一点也很重要。比如，因为提取了边缘的层的下一层能够使用边缘的信息，所以应该能够高效地学习更加高级的模式。也就是说，通过加深层，可以将各层要学习的问题分解成容易解决的简单问题，从而可以进行高效的学习。</p>
<p>以上就是对加深层的重要性的増补性说明。不过，这里需要注意的是，近几年的深层化是由大数据、计算能力等即便加深层也能正确地进行学习的新技术和环境支撑的。</p>
<h2 id="深度学习的小历史"><a href="#深度学习的小历史" class="headerlink" title="深度学习的小历史"></a>深度学习的小历史</h2><p>一般认为，现在深度学习之所以受到大量关注，其契机是 2012 年举办的大规模图像识别大赛 ILSVRC（ImageNet Large Scale Visual Recognition Challenge）。在那年的比赛中，基于深度学习的方法（通称 AlexNet）以压倒性的优势胜出，彻底颠覆了以往的图像识别方法。2012 年深度学习的这场逆袭成为一个转折点，在之后的比赛中，深度学习一直活跃在舞台中央。本节我们以 ILSVRC 这个大规模图像识别比赛为轴，看一下深度学习最近的发展趋势。</p>
<h3 id="ImageNet"><a href="#ImageNet" class="headerlink" title="ImageNet"></a>ImageNet</h3><p>ImageNet[25] 是拥有超过 100 万张图像的数据集。如图 8-7 所示，它包含了各种各样的图像，并且每张图像都被关联了标签（类别名）。每年都会举办使用这个巨大数据集的 ILSVRC 图像识别大赛。</p>
<p><img src="https://ws4.sinaimg.cn/large/006tKfTcly1g09sew4z9tj30rs09dan6.jpg" alt="150"></p>
<p><strong>图 8-7　大规模数据集 ImageNet 的数据例</strong></p>
<p>ILSVRC 大赛有多个测试项目，其中之一是“类别分类”（classification），在该项目中，会进行 1000 个类别的分类，比试识别精度。我们来看一下最近几年的 ILSVRC 大赛的类别分类项目的结果。图 8-8 中展示了从 2010 年到 2015 年的优胜队伍的成绩。这里，将前 5 类中出现正确解的情况视为“正确”，此时的错误识别率用柱形图来表示。</p>
<p>图 8-8 中需要注意的是，以 2012 年为界，之后基于深度学习的方法一直居于首位。实际上，我们发现 2012 年的 AlexNet 大幅降低了错误识别率。并且，此后基于深度学习的方法不断在提升识别精度。特别是 2015 年的 ResNet（一个超过 150 层的深度网络）将错误识别率降低到了 3.5%。据说这个结果甚至超过了普通人的识别能力。</p>
<p><img src="https://note.youdao.com/yws/api/personal/file/WEBf66009af2a301e67fb5143f04fbe564d?method=download&amp;shareKey=088f2466a30bf4125649031a04299957" alt=""><br>图 8-8　ILSCRV 优胜队伍的成绩演变：竖轴是错误识别率，横轴是年份。横轴的括号内是队伍名或者方法名</p>
<p>ImageNet 挑战赛，举办从2010年到2017年。</p>
<h3 id="VGG"><a href="#VGG" class="headerlink" title="VGG"></a>VGG</h3><p>VGG 是由卷积层和池化层构成的基础的 CNN。不过，如图 8-9 所示，它的特点在于将有权重的层（卷积层或者全连接层）叠加至 16 层（或者 19 层），具备了深度（根据层的深度，有时也称为“VGG16”或“VGG19”）。</p>
<p>VGG 中需要注意的地方是，基于 3×3 的小型滤波器的卷积层的运算是连续进行的。如图 8-9 所示，重复进行“卷积层重叠 2 次到 4 次，再通过池化层将大小减半”的处理，最后经由全连接层输出结果。</p>
<pre class=" language-text"><code class="language-text">VGG 在 2014 年的比赛中最终获得了第 2 名的成绩（下一节介绍的 GoogleNet 是 2014 年的第 1 名）。虽然在性能上不及 GoogleNet，但因为 VGG 结构简单，应用性强，所以很多技术人员都喜欢使用基于 VGG 的网络。
</code></pre>
<p><img src="https://ws1.sinaimg.cn/large/006tKfTcly1g09sjes7wzj30rs0ci0ux.jpg" alt="152"></p>
<p><strong>图 8-9　VGG</strong></p>
<h3 id="GoogLeNet"><a href="#GoogLeNet" class="headerlink" title="GoogLeNet"></a>GoogLeNet</h3><p>GoogLeNet 的网络结构如图 8-10 所示。图中的矩形表示卷积层、池化层等。</p>
<p><img src="https://ws1.sinaimg.cn/large/006tKfTcly1g09skjmfk2j30rs065aci.jpg" alt="153"></p>
<p><strong>图 8-10　GoogLeNet</strong></p>
<p>只看图的话，这似乎是一个看上去非常复杂的网络结构，但实际上它基本上和之前介绍的 CNN 结构相同。不过，GoogLeNet 的特征是，网络不仅在纵向上有深度，在横向上也有深度（广度）。</p>
<p>GoogLeNet 在横向上有“宽度”，这称为“Inception 结构”，以图 8-11 所示的结构为基础。</p>
<p>如图 8-11 所示，Inception 结构使用了多个大小不同的滤波器（和池化），最后再合并它们的结果。GoogLeNet 的特征就是将这个 Inception 结构用作一个构件（构成元素）。此外，在 GoogLeNet 中，很多地方都使用了大小为 1 × 1 的滤波器的卷积层。这个 1 × 1 的卷积运算通过在通道方向上减小大小，有助于减少参数和实现高速化处理。</p>
<p><img src="https://ws4.sinaimg.cn/large/006tKfTcly1g09slvuonqj30rs0d3tam.jpg" alt="154"></p>
<p><strong>图 8-11　GoogLeNet 的 Inception 结构</strong></p>
<h3 id="ResNet"><a href="#ResNet" class="headerlink" title="ResNet"></a>ResNet</h3><p>ResNet[24] 是微软团队开发的网络。它的特征在于具有比以前的网络更深的结构。</p>
<p>我们已经知道加深层对于提升性能很重要。但是，在深度学习中，过度加深层的话，很多情况下学习将不能顺利进行，导致最终性能不佳。ResNet 中，为了解决这类问题，导入了“快捷结构”（也称为“捷径”或“小路”）。导入这个快捷结构后，就可以随着层的加深而不断提高性能了（当然，层的加深也是有限度的）。</p>
<p>如图 8-12 所示，快捷结构横跨（跳过）了输入数据的卷积层，将输入 <code>x</code> 合计到输出。</p>
<p>图 8-12 中，在连续 2 层的卷积层中，将输入 <em>x</em> 跳着连接至 2 层后的输出。这里的重点是，通过快捷结构，原来的 2 层卷积层的输出${F}(x)$变成了${F}(x)+x$。通过引入这种快捷结构，即使加深层，也能高效地学习。这是因为，通过快捷结构，反向传播时信号可以无衰减地传递。</p>
<p><img src="https://ws2.sinaimg.cn/large/006tKfTcly1g09sohy3gkj30rs0fp0v1.jpg" alt="155"></p>
<p><strong>图 8-12　ResNet 的构成要素（引用自文献 [24]）：这里的“weight layer”是指卷积层</strong></p>
<pre class=" language-text"><code class="language-text">因为快捷结构只是原封不动地传递输入数据，所以反向传播时会将来自上游的梯度原封不动地传向下游。这里的重点是不对来自上游的梯度进行任何处理，将其原封不动地传向下游。因此，基于快捷结构，不用担心梯度会变小（或变大），能够向前一层传递“有意义的梯度”。通过这个快捷结构，之前因为加深层而导致的梯度变小的梯度消失问题就有望得到缓解。
</code></pre>
<p>ResNet 以前面介绍过的 VGG 网络为基础，引入快捷结构以加深层，其结果如图 8-13 所示。</p>
<p><img src="https://ws1.sinaimg.cn/large/006tKfTcly1g09spjhmazj30rs03umzu.jpg" alt="156"></p>
<p><strong>图 8-13　ResNet（引用自文献 [24]）：方块对应 3×3 的卷积层，其特征在于引入了横跨层的快捷结构</strong></p>
<p>如图 8-13 所示，ResNet 通过以 2 个卷积层为间隔跳跃式地连接来加深层。另外，根据实验的结果，即便加深到 150 层以上，识别精度也会持续提高。并且，在 ILSVRC 大赛中，ResNet 的错误识别率为 3.5%（前 5 类中包含正确解这一精度下的错误识别率），令人称奇。</p>
<pre class=" language-text"><code class="language-text">实践中经常会灵活应用使用 ImageNet 这个巨大的数据集学习到的权重数据，这称为迁移学习，将学习完的权重（的一部分）复制到其他神经网络，进行再学习（fine tuning）。比如，准备一个和 VGG 相同结构的网络，把学习完的权重作为初始值，以新数据集为对象，进行再学习。迁移学习在手头数据集较少时非常有效。
</code></pre>
<h2 id="深度学习的高速化"><a href="#深度学习的高速化" class="headerlink" title="深度学习的高速化"></a>深度学习的高速化</h2><p>随着大数据和网络的大规模化，深度学习需要进行大量的运算。虽然到目前为止，我们都是使用 CPU 进行计算的，但现实是只用 CPU 来应对深度学习无法令人放心。实际上，环视一下周围，大多数深度学习的框架都支持 <strong>GPU</strong>（Graphics Processing Unit），可以高速地处理大量的运算。另外，最近的框架也开始支持多个 GPU 或多台机器上的分布式学习。本节我们将焦点放在深度学习的计算的高速化上，然后逐步展开。深度学习的实现在 8.1 节就结束了，本节要讨论的高速化（支持 GPU 等）并不进行实现。</p>
<h3 id="需要努力解决的问题"><a href="#需要努力解决的问题" class="headerlink" title="需要努力解决的问题"></a>需要努力解决的问题</h3><p>在介绍深度学习的高速化之前，我们先来看一下深度学习中什么样的处理比较耗时。图 8-14 中以 AlexNet 的 <code>forward</code> 处理为对象，用饼图展示了各层所耗费的时间。</p>
<p>从图中可知，AlexNex 中，大多数时间都被耗费在卷积层上。实际上，卷积层的处理时间加起来占 GPU 整体的 95%，占 CPU 整体的 89% ！因此，如何高速、高效地进行卷积层中的运算是深度学习的一大课题。虽然图 8-14 是推理时的结果，不过学习时也一样，卷积层中会耗费大量时间。</p>
<pre class=" language-text"><code class="language-text">正如 7.2 节介绍的那样，卷积层中进行的运算可以追溯至乘积累加运算。因此，深度学习的高速化的主要课题就变成了如何高速、高效地进行大量的乘积累加运算。
</code></pre>
<p><img src="https://ws3.sinaimg.cn/large/006tKfTcly1g09srrzgnpj30rs09kwin.jpg" alt="157"></p>
<p><strong>图 8-14　AlexNet 的 forward 处理中各层的时间比：左边是使用 GPU 的情况，右边是使用 CPU 的情况。图中的“conv”对应卷积层，“pool”对应池化层，“fc”对应全连接层，“norm”对应正规化层（引用自文献 [26]）</strong></p>
<h3 id="基于GPU的高速化"><a href="#基于GPU的高速化" class="headerlink" title="基于GPU的高速化"></a>基于GPU的高速化</h3><p>GPU 原本是作为图像专用的显卡使用的，但最近不仅用于图像处理，也用于通用的数值计算。由于 GPU 可以高速地进行并行数值计算，因此 <strong>GPU 计算</strong>的目标就是将这种压倒性的计算能力用于各种用途。所谓 GPU 计算，是指基于 GPU 进行通用的数值计算的操作。</p>
<p>深度学习中需要进行大量的乘积累加运算（或者大型矩阵的乘积运算）。这种大量的并行运算正是 GPU 所擅长的（反过来说，CPU 比较擅长连续的、复杂的计算）。因此，与使用单个 CPU 相比，使用 GPU 进行深度学习的运算可以达到惊人的高速化。下面我们就来看一下基于 GPU 可以实现多大程度的高速化。图 8-15 是基于 CPU 和 GPU 进行 AlexNet 的学习时分别所需的时间。</p>
<p>从图中可知，使用 CPU 要花 40 天以上的时间，而使用 GPU 则可以将时间缩短至 6 天。此外，还可以看出，通过使用 cuDNN 这个最优化的库，可以进一步实现高速化。</p>
<p>GPU 主要由 NVIDIA 和 AMD 两家公司提供。虽然两家的 GPU 都可以用于通用的数值计算，但与深度学习比较“亲近”的是 NVIDIA 的 GPU。实际上，大多数深度学习框架只受益于 NVIDIA 的 GPU。这是因为深度学习的框架中使用了 NVIDIA 提供的 CUDA 这个面向 GPU 计算的综合开发环境。图 8-15 中出现的 cuDNN 是在 CUDA 上运行的库，它里面实现了为深度学习最优化过的函数等。</p>
<p><img src="https://ws3.sinaimg.cn/large/006tKfTcly1g09ssz0cfpj30rs0iedho.jpg" alt="158"></p>
<p><strong>图 8-15　使用 CPU 的“16-core Xeon CPU”和 GPU 的“Titan 系列”进行 AlexNet 的学习时分别所需的时间（引用自文献 [27]）</strong></p>
<pre class=" language-text"><code class="language-text">通过 im2col 可以将卷积层进行的运算转换为大型矩阵的乘积。这个 im2col 方式的实现对 GPU 来说是非常方便的实现方式。这是因为，相比按小规模的单位进行计算，GPU 更擅长计算大规模的汇总好的数据。也就是说，通过基于 im2col 以大型矩阵的乘积的方式汇总计算，更容易发挥出 GPU 的能力。
</code></pre>
<h3 id="分布式学习"><a href="#分布式学习" class="headerlink" title="分布式学习"></a>分布式学习</h3><p>虽然通过 GPU 可以实现深度学习运算的高速化，但即便如此，当网络较深时，学习还是需要几天到几周的时间。并且，前面也说过，深度学习伴随着很多试错。为了创建良好的网络，需要反复进行各种尝试，这样一来就必然会产生尽可能地缩短一次学习所需的时间的要求。于是，将深度学习的学习过程扩展开来的想法（也就是分布式学习）就变得重要起来。</p>
<p>为了进一步提高深度学习所需的计算的速度，可以考虑在多个 GPU 或者多台机器上进行分布式计算。现在的深度学习框架中，出现了好几个支持多 GPU 或者多机器的分布式学习的框架。其中，Google 的 TensorFlow、微软的 CNTK（Computational Network Toolki）在开发过程中高度重视分布式学习。以大型数据中心的低延迟·高吞吐网络作为支撑，基于这些框架的分布式学习呈现出惊人的效果。</p>
<p>基于分布式学习，可以达到何种程度的高速化呢？图 8-16 中显示了基于 TensorFlow 的分布式学习的效果。</p>
<p><img src="https://ws3.sinaimg.cn/large/006tKfTcly1g09su1uq91j30rs0ftdh9.jpg" alt="159"></p>
<p><strong>图 8-16　基于 TensorFlow 的分布式学习的效果：横轴是 GPU 的个数，纵轴是与单个 GPU 相比时的高速化率（引用自文献 [28]）</strong></p>
<p>如图 8-16 所示，随着 GPU 个数的增加，学习速度也在提高。实际上，与使用 1 个 GPU 时相比，使用 100 个 GPU（设置在多台机器上，共 100 个）似乎可以实现 56 倍的高速化！这意味着之前花费 7 天的学习只要 3 个小时就能完成，充分说明了分布式学习惊人的效果。</p>
<p>关于分布式学习，“如何进行分布式计算”是一个非常难的课题。它包含了机器间的通信、数据的同步等多个无法轻易解决的问题。可以将这些难题都交给 TensorFlow 等优秀的框架。这里，我们不讨论分布式学习的细节。关于分布式学习的技术性内容，请参考 TensorFlow 的技术论文（白皮书）等。</p>
<h3 id="运算精度的位数缩减"><a href="#运算精度的位数缩减" class="headerlink" title="运算精度的位数缩减"></a>运算精度的位数缩减</h3><p>在深度学习的高速化中，除了计算量之外，内存容量、总线带宽等也有可能成为瓶颈。关于内存容量，需要考虑将大量的权重参数或中间数据放在内存中。关于总线带宽，当流经 GPU（或者 CPU）总线的数据超过某个限制时，就会成为瓶颈。考虑到这些情况，我们希望尽可能减少流经网络的数据的位数。</p>
<p>计算机中为了表示实数，主要使用 64 位或者 32 位的浮点数。通过使用较多的位来表示数字，虽然数值计算时的误差造成的影响变小了，但计算的处理成本、内存使用量却相应地增加了，还给总线带宽带来了负荷。</p>
<p>关于数值精度（用几位数据表示数值），我们已经知道深度学习并不那么需要数值精度的位数。这是神经网络的一个重要性质。这个性质是基于神经网络的健壮性而产生的。这里所说的健壮性是指，比如，即便输入图像附有一些小的噪声，输出结果也仍然保持不变。可以认为，正是因为有了这个健壮性，流经网络的数据即便有所“劣化”，对输出结果的影响也较小。</p>
<p>计算机中表示小数时，有 32 位的单精度浮点数和 64 位的双精度浮点数等格式。根据以往的实验结果，在深度学习中，即便是 16 位的<strong>半精度浮点数</strong>（half float），也可以顺利地进行学习 [30]。实际上，NVIDIA 的下一代 GPU 框架 Pascal 也支持半精度浮点数的运算，由此可以认为今后半精度浮点数将被作为标准使用。</p>
<pre class=" language-text"><code class="language-text">NVIDIA 的 Maxwell GPU 虽然支持半精度浮点数的存储（保存数据的功能），但是运算本身不是用 16 位进行的。下一代的 Pascal 框架，因为运算也是用 16 位进行的，所以只用半精度浮点数进行计算，就有望实现超过上一代 GPU 约 2 倍的高速化。
</code></pre>
<p>以往的深度学习的实现中并没有注意数值的精度，不过 Python 中一般使用 64 位的浮点数。NumPy 中提供了 16 位的半精度浮点数类型（不过，只有 16 位类型的存储，运算本身不用 16 位进行），即便使用 NumPy 的半精度浮点数，识别精度也不会下降。</p>
<p>关于深度学习的位数缩减，到目前为止已有若干研究。最近有人提出了用 1 位来表示权重和中间数据的 Binarized Neural Networks 方法 [31]。为了实现深度学习的高速化，位数缩减是今后必须关注的一个课题，特别是在面向嵌入式应用程序中使用深度学习时，位数缩减非常重要。</p>
<h2 id="深度学习的应用案例"><a href="#深度学习的应用案例" class="headerlink" title="深度学习的应用案例"></a>深度学习的应用案例</h2><p>前面，作为使用深度学习的例子，我们主要讨论了手写数字识别的图像类别分类问题（称为“物体识别”）。不过，深度学习并不局限于物体识别，还可以应用于各种各样的问题。此外，在图像、语音、自然语言等各个不同的领域，深度学习都展现了优异的性能。本节将以计算机视觉这个领域为中心，介绍几个深度学习能做的事情（应用）。</p>
<h3 id="物体检测"><a href="#物体检测" class="headerlink" title="物体检测"></a>物体检测</h3><p>物体检测是从图像中确定物体的位置，并进行分类的问题。如图 8-17 所示，要从图像中确定物体的种类和物体的位置。</p>
<p><img src="https://ws3.sinaimg.cn/large/006tKfTcly1g09sx1gedhj30rs0dhdyo.jpg" alt="160"></p>
<p><strong>图 8-17　物体检测的例子</strong></p>
<p>观察图 8-17 可知，物体检测是比物体识别更难的问题。之前介绍的物体识别是以整个图像为对象的，但是物体检测需要从图像中确定类别的位置，而且还有可能存在多个物体。</p>
<p>对于这样的物体检测问题，人们提出了多个基于 CNN 的方法。这些方法展示了非常优异的性能，并且证明了在物体检测的问题上，深度学习是非常有效的。</p>
<p>在使用 CNN 进行物体检测的方法中，有一个叫作 R-CNN[35] 的有名的方法。图 8-18 显示了 R-CNN 的处理流。</p>
<p><img src="https://ws4.sinaimg.cn/large/006tKfTcly1g09sxu3ogyj30rs07w45a.jpg" alt="161"></p>
<p><strong>图 8-18　R-CNN 的处理流</strong></p>
<p>希望大家注意图中的“2.Extract region proposals”（候选区域的提取）和“3.Compute CNN features”（CNN 特征的计算）的处理部分。这里，首先（以某种方法）找出形似物体的区域，然后对提取出的区域应用 CNN 进行分类。R-CNN 中会将图像变形为正方形，或者在分类时使用 SVM（支持向量机），实际的处理流会稍微复杂一些，不过从宏观上看，也是由刚才的两个处理（候选区域的提取和 CNN 特征的计算）构成的。</p>
<p>在 R-CNN 的前半部分的处理——候选区域的提取（发现形似目标物体的处理）中，可以使用计算机视觉领域积累的各种各样的方法。R-CNN 的论文中使用了一种被称为 Selective Search 的方法，最近还提出了一种基于 CNN 来进行候选区域提取的 Faster R-CNN 方法 [36]。Faster R-CNN 用一个 CNN 来完成所有处理，使得高速处理成为可能。</p>
<h3 id="图像分割"><a href="#图像分割" class="headerlink" title="图像分割"></a>图像分割</h3><p>图像分割是指在像素水平上对图像进行分类。如图 8-19 所示，使用以像素为单位对各个对象分别着色的监督数据进行学习。然后，在推理时，对输入图像的所有像素进行分类。</p>
<p><img src="https://ws2.sinaimg.cn/large/006tKfTcly1g09sz7u0wvj30rs0ai7bu.jpg" alt="162"></p>
<p><strong>图 8-19　图像分割的例子（引用自文献 [34]）：左边是输入图像，右边是监督用的带标签图像</strong></p>
<p>之前实现的神经网络是对图像整体进行了分类，要将它落实到像素水平的话，该怎么做呢？</p>
<p>要基于神经网络进行图像分割，最简单的方法是以所有像素为对象，对每个像素执行推理处理。比如，准备一个对某个矩形区域中心的像素进行分类的网络，以所有像素为对象执行推理处理。正如大家能想到的，这样的方法需要按照像素数量进行相应次 <code>forward</code> 处理，因而需要耗费大量的时间（正确地说，卷积运算中会发生重复计算很多区域的无意义的计算）。为了解决这个无意义的计算问题，有人提出了一个名为 FCN（Fully Convolutional Network）[37] 的方法。该方法通过一次 <code>forward</code> 处理，对所有像素进行分类（图 8-20）。</p>
<p>FCN 的字面意思是“全部由卷积层构成的网络”。相对于一般的 CNN 包含全连接层，FCN 将全连接层替换成发挥相同作用的卷积层。在物体识别中使用的网络的全连接层中，中间数据的空间容量被作为排成一列的节点进行处理，而只由卷积层构成的网络中，空间容量可以保持原样直到最后的输出。</p>
<p>如图 8-20 所示，FCN 的特征在于最后导入了扩大空间大小的处理。基于这个处理，变小了的中间数据可以一下子扩大到和输入图像一样的大小。FCN 最后进行的扩大处理是基于双线性插值法的扩大（双线性插值扩大）。FCN 中，这个双线性插值扩大是通过去卷积（逆卷积运算）来实现的（细节请参考 FCN 的论文 [37]）。</p>
<p><img src="https://ws2.sinaimg.cn/large/006tKfTcly1g09t0t41j0j30rs0ejn2f.jpg" alt="163"></p>
<p><strong>图 8-20　FCN 的概略图</strong></p>
<pre class=" language-text"><code class="language-text">全连接层中，输出和全部的输入相连。使用卷积层也可以实现与此结构完全相同的连接。比如，针对输入大小是 32×10×10（通道数 32、高 10、长 10）的数据的全连接层可以替换成滤波器大小为 32×10×10 的卷积层。如果全连接层的输出节点数是 100，那么在卷积层准备 100 个 32×10×10 的滤波器就可以实现完全相同的处理。像这样，全连接层可以替换成进行相同处理的卷积层。
</code></pre>
<h3 id="图像标题的生成"><a href="#图像标题的生成" class="headerlink" title="图像标题的生成"></a>图像标题的生成</h3><p>有一项融合了计算机视觉和自然语言的有趣的研究，该研究如图 8-21 所示，给出一个图像后，会自动生成介绍这个图像的文字（图像的标题）。</p>
<p>给出一个图像后，会像图 8-21 一样自动生成表示该图像内容的文本。比如，左上角的第一幅图像生成了文本“A person riding a motorcycle on a dirt road.”（在没有铺装的道路上骑摩托车的人），而且这个文本只从该图像自动生成。文本的内容和图像确实是一致的。并且，令人惊讶的是，除了“骑摩托车”之外，连“没有铺装的道路”都被正确理解了。</p>
<p><img src="https://ws4.sinaimg.cn/large/006tKfTcly1g09t24ib3cj30rs0hd7rq.jpg" alt="164"></p>
<p><strong>图 8-21　基于深度学习的图像标题生成的例子（引用自文献 [38]）</strong></p>
<p>一个基于深度学习生成图像标题的代表性方法是被称为 NIC（Neural Image Caption）的模型。如图 8-22 所示，NIC 由深层的 CNN 和处理自然语言的 RNN（Recurrent Neural Network）构成。RNN 是呈递归式连接的网络，经常被用于自然语言、时间序列数据等连续性的数据上。</p>
<p><img src="https://ws3.sinaimg.cn/large/006tKfTcly1g09t2qppkcj30rs0audpu.jpg" alt="165"></p>
<p><strong>图 8-22　Neural Image Caption（NIC）的整体结构</strong></p>
<p>NIC 基于 CNN 从图像中提取特征，并将这个特征传给 RNN。RNN 以 CNN 提取出的特征为初始值，递归地生成文本。这里，我们不深入讨论技术上的细节，不过基本上 NIC 是组合了两个神经网络（CNN 和 RNN）的简单结构。基于 NIC，可以生成惊人的高精度的图像标题。我们将组合图像和自然语言等多种信息进行的处理称为<strong>多模态处理</strong>。多模态处理是近年来备受关注的一个领域。</p>
<pre class=" language-text"><code class="language-text">RNN 的 R 表示 Recurrent（递归的）。这个递归指的是神经网络的递归的网络结构。根据这个递归结构，神经网络会受到之前生成的信息的影响（换句话说，会记忆过去的信息），这是 RNN 的特征。比如，生成“我”这个词之后，下一个要生成的词受到“我”这个词的影响，生成了“要”；然后，再受到前面生成的“我要”的影响，生成了“睡觉”这个词。对于自然语言、时间序列数据等连续性的数据，RNN 以记忆过去的信息的方式运行。
</code></pre>
<h2 id="深度学习的未来"><a href="#深度学习的未来" class="headerlink" title="深度学习的未来"></a>深度学习的未来</h2><p>深度学习已经不再局限于以往的领域，开始逐渐应用于各个领域。本节将介绍几个揭示了深度学习的可能性和未来的研究。</p>
<h3 id="图像风格变换"><a href="#图像风格变换" class="headerlink" title="图像风格变换"></a>图像风格变换</h3><p>有一项研究是使用深度学习来“绘制”带有艺术气息的画。如图 8-23 所示，输入两个图像后，会生成一个新的图像。两个输入图像中，一个称为“内容图像”，另一个称为“风格图像”。</p>
<p>如图 8-23 所示，如果指定将梵高的绘画风格应用于内容图像，深度学习就会按照指示绘制出新的画作。此项研究出自论文“A Neural Algorithm of Artistic Style”[39]，一经发表就受到全世界的广泛关注。</p>
<p><img src="https://ws4.sinaimg.cn/large/006tKfTcly1g09t48nvogj30rs0mt7wh.jpg" alt="166"></p>
<p><strong>图 8-23　基于论文“A Neural Algorithm of Artistic Style”的图像风格变换的例子：左上角是风格图像，右上角是内容图像，下面的图像是新生成的图像（图像引用自文献[40]）</strong></p>
<p>这里我们不会介绍这项研究的详细内容，只是叙述一下这个技术的大致框架，即刚才的方法是在学习过程中使网络的中间数据近似内容图像的中间数据。这样一来，就可以使输入图像近似内容图像的形状。此外，为了从风格图像中吸收风格，导入了风格矩阵的概念。通过在学习过程中减小风格矩阵的偏差，就可以使输入图像接近梵高的风格。</p>
<h3 id="图像的生成"><a href="#图像的生成" class="headerlink" title="图像的生成"></a>图像的生成</h3><p>刚才的图像风格变换的例子在生成新的图像时输入了两个图像。不同于这种研究，现在有一种研究是生成新的图像时不需要任何图像（虽然需要事先使用大量的图像进行学习，但在“画”新图像时不需要任何图像）。比如，基于深度学习，可以实现从零生成“卧室”的图像。图 8-24 中展示的图像是基于 <strong>DCGAN</strong>（Deep Convolutional Generative Adversarial Network）[41] 方法生成的卧室图像的例子。</p>
<p><img src="https://ws1.sinaimg.cn/large/006tKfTcly1g09t5jzlygj30rs0dxat1.jpg" alt="167"></p>
<p><strong>图 8-24　基于 DCGAN 生成的新的卧室图像（引用自文献 [41]）</strong></p>
<p>图 8-24 的图像可能看上去像是真的照片，但其实这些图像都是基于 DCGAN 新生成的图像。也就是说，DCGAN 生成的图像是谁都没有见过的图像（学习数据中没有的图像），是从零生成的新图像。</p>
<p>能画出以假乱真的图像的 DCGAN 会将图像的生成过程模型化。使用大量图像（比如，印有卧室的大量图像）训练这个模型，学习结束后，使用这个模型，就可以生成新的图像。</p>
<p>DCGAN 中使用了深度学习，其技术要点是使用了 Generator（生成者）和 Discriminator（识别者）这两个神经网络。Generator 生成近似真品的图像，Discriminator 判别它是不是真图像（是 Generator 生成的图像还是实际拍摄的图像）。像这样，通过让两者以竞争的方式学习，Generator 会学习到更加精妙的图像作假技术，Discriminator 则会成长为能以更高精度辨别真假的鉴定师。两者互相切磋、共同成长，这是 <strong>GAN</strong>（Generative Adversarial Network）这个技术的有趣之处。在这样的切磋中成长起来的 Generator 最终会掌握画出足以以假乱真的图像的能力（或者说有这样的可能）。</p>
<pre class=" language-text"><code class="language-text">之前我们见到的机器学习问题都是被称为监督学习（supervised learning）的问题。这类问题就像手写数字识别一样，使用的是图像数据和教师标签成对给出的数据集。不过这里讨论的问题，并没有给出监督数据，只给了大量的图像（图像的集合），这样的问题称为无监督学习（unsupervised learning）。无监督学习虽然是很早之前就开始研究的领域（Deep Belief Network、Deep Boltzmann Machine 等很有名），但最近似乎并不是很活跃。今后，随着使用深度学习的 DCGAN 等方法受到关注，无监督学习有望得到进一步发展。
</code></pre>
<h3 id="自动驾驶"><a href="#自动驾驶" class="headerlink" title="自动驾驶"></a>自动驾驶</h3><p>计算机代替人类驾驶汽车的自动驾驶技术有望得到实现。除了汽车制造商之外，IT 企业、大学、研究机构等也都在为实现自动驾驶而进行着激烈的竞争。自动驾驶需要结合各种技术的力量来实现，比如决定行驶路线的路线计划（path plan）技术、照相机或激光等传感技术等，在这些技术中，正确识别周围环境的技术据说尤其重要。这是因为要正确识别时刻变化的环境、自由来往的车辆和行人是非常困难的。</p>
<p>如果可以在各种环境中稳健地正确识别行驶区域的话，实现自动驾驶可能也就没那么遥远了。最近，在识别周围环境的技术中，深度学习的力量备受期待。比如，基于 CNN 的神经网络 SegNet[42]，可以像图 8-25 那样高精度地识别行驶环境。</p>
<p>图 8-25 中对输入图像进行了分割（像素水平的判别）。观察结果可知，在某种程度上正确地识别了道路、建筑物、人行道、树木、车辆等。今后若能基于深度学习使这种技术进一步实现高精度化、高速化的话，自动驾驶的实用化可能也就没那么遥远了。</p>
<p><img src="https://ws1.sinaimg.cn/large/006tKfTcly1g09t6vq8a4j30rs0d7n6y.jpg" alt="168"></p>
<p><strong>图 8-25　基于深度学习的图像分割的例子：道路、车辆、建筑物、人行道等被高精度地识别了出来（引用自文献 [43]）</strong></p>
<h3 id="Deep-Q-Network-强化学习"><a href="#Deep-Q-Network-强化学习" class="headerlink" title="Deep Q-Network (强化学习)"></a>Deep Q-Network (强化学习)</h3><p>就像人类通过摸索试验来学习一样（比如骑自行车），让计算机也在摸索试验的过程中自主学习，这称为<strong>强化学习</strong>（reinforcement learning）。强化学习和有“教师”在身边教的“监督学习”有所不同。</p>
<p>强化学习的基本框架是，代理（Agent）根据环境选择行动，然后通过这个行动改变环境。根据环境的变化，代理获得某种报酬。强化学习的目的是决定代理的行动方针，以获得更好的报酬（图 8-26）。</p>
<p>图 8-26 中展示了强化学习的基本框架。这里需要注意的是，报酬并不是确定的，只是“预期报酬”。比如，在《超级马里奥兄弟》这款电子游戏中，让马里奥向右移动能获得多少报酬不一定是明确的。这时需要从游戏得分（获得的硬币、消灭的敌人等）或者游戏结束等明确的指标来反向计算，决定“预期报酬”。如果是监督学习的话，每个行动都可以从“教师”那里获得正确的评价。</p>
<p><img src="https://ws2.sinaimg.cn/large/006tKfTcly1g09t7mnjiej30rp0nqaa2.jpg" alt="169"></p>
<p><strong>图 8-26　强化学习的基本框架：代理自主地进行学习，以获得更好的报酬</strong></p>
<p>在使用了深度学习的强化学习方法中，有一个叫作 Deep Q-Network（通称 <strong>DQN</strong>）[44] 的方法。该方法基于被称为 Q 学习的强化学习算法。这里省略 Q 学习的细节，不过在 Q 学习中，为了确定最合适的行动，需要确定一个被称为最优行动价值函数的函数。为了近似这个函数，DQN 使用了深度学习（CNN）。</p>
<p>在 DQN 的研究中，有让电子游戏自动学习，并实现了超过人类水平的操作的例子。如图 8-27 所示，DQN 中使用的 CNN 把游戏图像的帧（连续 4 帧）作为输入，最终输出游戏手柄的各个动作（控制杆的移动量、按钮操作的有无等）的“价值”。</p>
<p>之前在学习电子游戏时，一般是把游戏的状态（人物的地点等）事先提取出来，作为数据给模型。但是，在 DQN 中，如图 8-27 所示，输入数据只有电子游戏的图像。这是 DQN 值得大书特书的地方，可以说大幅提高了 DQN 的实用性。为什么呢？因为这样就无需根据每个游戏改变设置，只要给 DQN 游戏图像就可以了。实际上，DQN 可以用相同的结构学习《吃豆人》、<em>Atari</em> 等很多游戏，甚至在很多游戏中取得了超过人类的成绩。</p>
<p><img src="https://ws4.sinaimg.cn/large/006tKfTcly1g09t8zucn4j30rs0g1q84.jpg" alt="170"></p>
<p><strong>图 8-27　基于 Deep Q-Network 学习电子游戏的操作。输入是电子游戏的图像，经过摸索试验，学习出让专业玩家都自愧不如的游戏手柄（操作杆）的操作手法（引用自文献 [44]）</strong></p>
<pre class=" language-text"><code class="language-text">人工智能 AlphaGo[45] 击败围棋冠军的新闻受到了广泛关注。这个 AlphaGo 技术的内部也用了深度学习和强化学习。AlphaGo 学习了 3000 万个专业棋手的棋谱，并且不停地重复自己和自己的对战，积累了大量的学习经验。AlphaGo 和 DQN 都是 Google 的 Deep Mind 公司进行的研究，该公司今后的研究值得密切关注。
</code></pre>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>本章我们实现了一个（稍微）深层的 CNN，并在手写数字识别上获得了超过 99% 的高识别精度。此外，还讲解了加深网络的动机，指出了深度学习在朝更深的方向前进。之后，又介绍了深度学习的趋势和应用案例，以及对高速化的研究和代表深度学习未来的研究案例。</p>
<p>深度学习领域还有很多尚未揭晓的东西，新的研究正一个接一个地出现。今后，全世界的研究者和技术专家也将继续积极从事这方面的研究，一定能实现目前无法想象的技术。</p>
<p>主要内容包括：</p>
<ul>
<li>对于大多数的问题，都可以期待通过加深网络来提高性能。</li>
<li>在最近的图像识别大赛ILSVRC中，基于深度学习的方法独占鳌头，使用的网络也在深化。</li>
<li>VGG、GoogLeNet、ResNet等是几个著名的网络。</li>
<li>基于GPU、分布式学习、位数精度的缩减，可以实现深度学习的高速化。</li>
<li>深度学习（神经网络）不仅可以用于物体识别，还可以用于物体检测、图像分割。</li>
<li>深度学习的应用包括图像标题的生成、图像的生成、强化学习等。最近，深度学习在自动驾驶上的应用也备受期待。</li>
</ul>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ol>
<li><a href="http://www.ituring.com.cn/book/1921" target="_blank" rel="noopener">深度学习入门：基于Python的理论与实现</a></li>
</ol>

            </div>
            <hr>

            
            <style>
    #reward {
        margin: 40px 0;
        text-align: center;
    }

    #reward .reward-link {
        font-size: 1.88rem;
    }

    #reward .btn-floating:hover {
        box-shadow: 0 6px 12px rgba(0, 0, 0, 0.2), 0 5px 15px rgba(0, 0, 0, 0.2);
    }

    #rewardModal {
        width: 320px;
        height: 350px;
    }

    #rewardModal .reward-title {
        margin: 15px auto;
        padding-bottom: 5px;
    }

    #rewardModal .modal-content {
        padding: 10px;
    }

    #rewardModal .close {
        position: absolute;
        right: 15px;
        top: 15px;
        color: rgba(0, 0, 0, 0.5);
        font-size: 1.3rem;
        line-height: 20px;
        cursor: pointer;
    }

    #rewardModal .reward-tabs {
        margin: 0 auto;
        width: 210px;
    }

    .reward-tabs .tabs {
        height: 38px;
        margin: 10px auto;
        padding-left: 0;
    }

    .reward-tabs .tabs .tab {
        height: 38px;
        line-height: 38px;
    }

    .reward-tabs .tab a {
        color: #fff;
        background-color: #ccc;
    }

    .reward-tabs .tab a:hover {
        color: #fff;
    }

    .reward-tabs .wechat-tab .active {
        color: #fff;
        background-color: #22AB38;
    }

    .reward-tabs .alipay-tab .active {
        color: #fff;
        background-color: #019FE8;
    }

    .reward-tabs .reward-img {
        width: 210px;
        height: 210px;
    }
</style>

<div id="reward">
    <a class="reward-link btn-floating btn-large waves-effect waves-light red">赏</a>

    <!-- Modal Structure -->
    <div id="rewardModal" class="modal">
        <div class="modal-content">
            <a class="close"><i class="fa fa-close"></i></a>
            <h4 class="reward-title">你的赏识是我前进的动力</h4>
            <div class="reward-content">
                <div class="reward-tabs">
                    <ul class="tabs">
                        <li class="tab wechat-tab waves-effect waves-light"><a class="active" href="#wechat">微信</a></li>
                        <li class="tab alipay-tab waves-effect waves-light"><a href="#alipay">支付宝</a></li>
                    </ul>
                    <div id="wechat">
                        <img src="/medias/reward/wechat.jpg" class="reward-img" alt="微信打赏二维码">
                    </div>
                    <div id="alipay">
                        <img src="/medias/reward/alipay.jpg" class="reward-img" alt="支付宝打赏二维码">
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>

<script>
    $(function () {
        $('#reward .reward-link').on('click', function () {
            $('#rewardModal').openModal();
        });

        $('#rewardModal .close').on('click', function () {
            $('#rewardModal').closeModal();
        });
    });
</script>
            

            <link rel="stylesheet" type="text/css" href="/libs/share/css/share.min.css">

<div id="article-share">
    
    <div class="social-share" data-disabled="qzone" data-wechat-qrcode-helper="<p>微信里点“发现”->“扫一扫”二维码便可查看分享。</p>"></div>
    
</div>

<script src="/libs/share/js/social-share.min.js"></script>

            <div class="reprint">
                <p>
                    <span class="reprint-tip">
                        <i class="fa fa-exclamation-circle"></i>&nbsp;&nbsp;转载请注明:
                    </span>
                    <a href="http://yuzhongchun.com" class="b-link-green">BerMaker</a>
                    <i class="fa fa-angle-right fa-lg fa-fw text-color"></i>
                    <a href="/2018/11/22/33-dl-deep-learning-notes/" class="b-link-green">Notes-深度学习入门之深度学习</a>
                </p>
            </div>
        </div>
    </div>

    
        <link rel="stylesheet" href="/libs/gitalk/gitalk.css">
<link rel="stylesheet" href="/css/my-gitalk.css">

<div class="card gitalk-card" data-aos="fade-up">
    <div id="gitalk-container" class="card-content"></div>
</div>

<script src="/libs/gitalk/gitalk.min.js"></script>
<script>
    let gitalk = new Gitalk({
        clientID: '21ea087c6104923ba888',
        clientSecret: '560f45f0aefc21d726f86ee331bb04fc8660bcf6',
        repo: 'gitalk',
        owner: 'zhongchun',
        admin: "zhongchun",
        id: '2018-11-22T21-35-32',
        distractionFreeMode: false  // Facebook-like distraction free mode
    });

    gitalk.render('gitalk-container');
</script>
    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fa fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/2018/11/24/34-a-small-project/">
                    <div class="card-image">
                        
                        <img src="/images/typewriter.jpg" class="responsive-img" alt="A Small End-to-End Project">
                        
                        <span class="card-title">A Small End-to-End Project</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary">Books and courses are frustrating. They give you lots of recipes and snippets, but you never get to see how they all fit</div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="fa fa-clock-o fa-fw icon-date"></i>2018-11-24
                        </span>
                        <span class="publish-author">
                            
                            <i class="fa fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/Machine-Learning/" class="post-category" target="_blank">
                                    Machine Learning
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/Machine-Learning/" target="_blank">
                        <span class="chip bg-color">Machine Learning</span>
                    </a>
                    
                    <a href="/tags/Python/" target="_blank">
                        <span class="chip bg-color">Python</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fa fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/2018/11/17/32-dl-convolutional-neural-network-notes/">
                    <div class="card-image">
                        
                        <img src="/images/cnn.jpg" class="responsive-img" alt="Notes-深度学习入门之卷积神经网络">
                        
                        <span class="card-title">Notes-深度学习入门之卷积神经网络</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary">本章的主题是卷积神经网络（Convolutional Neural Network，CNN）。CNN 被用于图像识别、语音识别等各种场合，在图像识别的比赛中，基于深度学习的方法几乎都以 CNN 为基础。
整体结构首先，来看一下 CNN 的网</div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="fa fa-clock-o fa-fw icon-date"></i>2018-11-17
                            </span>
                        <span class="publish-author">
                            
                            <i class="fa fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/Deep-Learning/" class="post-category" target="_blank">
                                    Deep Learning
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/Notes/" target="_blank">
                        <span class="chip bg-color">Notes</span>
                    </a>
                    
                    <a href="/tags/Deep-Learning/" target="_blank">
                        <span class="chip bg-color">Deep Learning</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>
</div>


<script>
    $('#articleContent').on('copy', function (e) {
        // IE8 or earlier browser is 'undefined'
        if (typeof window.getSelection === 'undefined') return;

        var selection = window.getSelection();
        // if the selection is short let's not annoy our users.
        if (('' + selection).length < Number.parseInt('120')) {
            return;
        }

        // create a div outside of the visible area and fill it with the selected text.
        var bodyElement = document.getElementsByTagName('body')[0];
        var newdiv = document.createElement('div');
        newdiv.style.position = 'absolute';
        newdiv.style.left = '-99999px';
        bodyElement.appendChild(newdiv);
        newdiv.appendChild(selection.getRangeAt(0).cloneContents());

        // we need a <pre> tag workaround.
        // otherwise the text inside "pre" loses all the line breaks!
        if (selection.getRangeAt(0).commonAncestorContainer.nodeName === 'PRE') {
            newdiv.innerHTML = "<pre>" + newdiv.innerHTML + "</pre>";
        }

        var url = document.location.href;
        newdiv.innerHTML += '<br />'
            + '来源: BerMaker<br />'
            + '作者: BerMaker<br />'
            + '链接: <a href="' + url + '">' + url + '</a><br />'
            + '本文章著作权归作者所有，任何形式的转载都请注明出处。';

        selection.selectAllChildren(newdiv);
        window.setTimeout(function () {bodyElement.removeChild(newdiv);}, 200);
    });
</script>

    </div>
    <div class="col l3 hide-on-med-and-down">
        <div class="toc-widget">
            <div class="toc-title"><i class="fa fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<script src="/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingSelector: 'h2, h3, h4'
        });

        // modify the toc link href to support Chinese.
        let i = 0;
        let tocHeading = 'toc-heading-';
        $('#toc-content a').each(function () {
            $(this).attr('href', '#' + tocHeading + (++i));
        });

        // modify the heading title id to support Chinese.
        i = 0;
        $('#articleContent').children('h2, h3, h4').each(function () {
            $(this).attr('id', tocHeading + (++i));
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });
    });
</script>
    

</main>


<footer class="page-footer bg-color">
    <div class="container row center-align">
        <div class="col s12 m8 l8 copy-right">
            本站由&copy;<a href="https://blinkfox.github.io/" target="_blank">Blinkfox</a>基于
            <a href="https://hexo.io/" target="_blank">Hexo</a> 的
            <a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">hexo-theme-matery</a>主题搭建.

            
                &nbsp;<i class="fa fa-area-chart"></i>&nbsp;站点总字数:&nbsp;
                <span class="white-color">77.3k</span>
            

            
			
                <br>
                
                <span id="busuanzi_container_site_pv">
                    <i class="fa fa-heart-o"></i>
                    本站总访问量 <span id="busuanzi_value_site_pv" class="white-color"></span>
                </span>
                
                
                <span id="busuanzi_container_site_uv">
                    <i class="fa fa-users"></i>
                    次,&nbsp;访客数 <span id="busuanzi_value_site_uv" class="white-color"></span> 人.
                </span>
                
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/zhongchun" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fa fa-github"></i>
    </a>



    <a href="mailto:495571751@qq.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fa fa-envelope-open"></i>
    </a>



    <a href="/atom.xml" class="tooltipped" target="_blank" data-tooltip="RSS 订阅" data-position="top" data-delay="50">
        <i class="fa fa-rss"></i>
    </a>

</div>
    </div>
</footer>

<div class="progress-bar"></div>


<!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fa fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字" class="search-input" autofocus>
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script src="/js/search.js"></script>
<script type="text/javascript">
    searchFunc("/" + "search.xml", 'searchInput', 'searchResult');
</script>
<!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fa fa-angle-up"></i>
    </a>
</div>


<script src="/libs/materialize/js/materialize.min.js"></script>
<script src="/libs/masonry/masonry.pkgd.min.js"></script>
<script src="/libs/aos/aos.js"></script>
<script src="/libs/scrollprogress/scrollProgress.min.js"></script>
<script src="/libs/lightGallery/js/lightgallery-all.min.js"></script>
<script src="/js/matery.js"></script>

<!-- Global site tag (gtag.js) - Google Analytics -->



    <script src="/libs/others/clicklove.js"></script>


    <script async src="/libs/others/busuanzi.pure.mini.js"></script>


</body>
</html>